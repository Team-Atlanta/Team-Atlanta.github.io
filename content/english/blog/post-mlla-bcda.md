---
title: "BCDA: The AI Detective Separating Real Bugs from False Alarms"
meta_title: ""
description: "A deep dive into BCDA, the AI agent that acts as a detective, analyzing potential vulnerability paths to distinguish genuine threats from false positives and creating detailed bug reports for exploitation."
date: 2025-09-07T11:00:00Z
image: "/images/blog/mlla/bcda_preview.png"
categories: ["Atlantis-Multilang"]
author: "Sangwoo Ji"
tags: ["mlla", "llm", "vulnerability-discovery", "static-analysis", "multi-agent", "bcda"]
draft: false
---


## üéØ From Potential Sink to Actionable Intelligence

BCDA(Bug Candidate Detection Agent)'s core mission is to address the fundamental challenge of lightweight sink analysis: distinguishing real vulnerabilities from false-positive noise.
When MCGA, our cartographer, flags a function containing a potentially vulnerable "sink" (such as a function that executes system commands), BCDA takes over.

Its job isn't just to say "yes" or "no."
BCDA performs a deep, multi-stage investigation powered by LLMs to produce a **Bug Inducing Thing (BIT)**.
A BIT is a high-fidelity, structured report detailing a confirmed vulnerability candidate.
It includes the exact location, the specific trigger conditions (like `if-else` branches), and a detailed analysis generated by LLMs.
This report becomes a detailed guide for our demolition expert, BGA, and the fuzzing stages.

To get there, BCDA follows a rigorous, four-step investigative process.

---

### Step 1: üîç Path Expansion and Pruning (Gathering the Evidence)

A simple call stack is like a list of locations a suspect has visited: it shows where they've been, but not what they did there or who else was involved.
It often misses crucial context from functions outside the direct call chain, such as utility or validation functions.

BCDA starts by **expanding the execution path**.
It receives the call path from the source (typically the harness) to the sink (flagged by MCGA) and uses Tree-sitter-based parsing to identify *every single function call* made along that path.
This expanded set of functions is then provided to an LLM.

But more data isn't always better.
To avoid analyzing irrelevant code, BCDA immediately applies **LLM-powered pruning**.
Since MCGA already hints at the *type of vulnerability* (e.g., Command Injection, XXE, Path Traversal), BCDA asks the LLM: ‚ÄúOf all these functions, which ones are truly relevant to this *vulnerability type*?‚Äù

The LLM responds with only the necessary functions, leaving BCDA with a rich but focused context for its investigation‚Äîmuch like a detective interviewing dozens of people but quickly narrowing in on the key witnesses.

### Step 2: üïµÔ∏è Vulnerability Classification (The Interrogation)

With the relevant code path established, BCDA begins its interrogation.
BCDA constructs a **sanitizer-specific prompt** for the LLM.
This isn't a generic question; it's a highly detailed briefing that includes:
* A clear explanation of the suspected vulnerability type.
* Common coding patterns and anti-patterns associated with that vulnerability.
* Effective strategies for detecting it in source code.

Armed with this domain knowledge and the expanded-and-pruned code path, the LLM analyzes the code path and makes a definitive judgment: does this path contain the suspected vulnerability, or is it a false alarm?

### Step 3: üîë Key Condition and Trigger Path Extraction (Reconstructing the Crime)

If the LLM confirms a vulnerability, BCDA's most critical task begins: identifying the **key conditions** required to trigger it.
A bug is useless if you can't reach it.
BCDA needs to find the exact sequence of `if` statements, `try-catch` blocks, and other conditional logic that unlocks the path to the vulnerable code.

Instead of overwhelming the LLM with the entire path at once, BCDA analyzes it **transition by transition**.
It focuses on one function call at a time, asking the LLM: "To get from `function A` to `function B`, what conditions must be true?"

This granular, step-by-step approach allows the LLM to focus its analysis and accurately identify critical decision points.
For example, it might determine that an `if (user.isAdmin())` check must evaluate to `true` or that control must flow into a `catch (Exception e)` block to reach the sink.

### Step 4: üìù BIT Generation (Filing the Case Report)

The investigation concludes with the creation of a **Bug Inducing Thing (BIT)**.
This isn't just a simple alert; it's a structured data object, optimized for the next stages of our pipeline.

Each BIT contains everything an exploitation agent needs to know:
* **Vulnerability Type:** The class of the bug (e.g., `COMMAND_INJECTION`).
* **Location:** The exact file path and line numbers.
* **Key Conditions:** A list of all branch conditions that must be satisfied.
* **Analysis Messages:** A log of the LLM's reasoning from each step.
* **Priority Level:** A score based on factors like how recently the code was changed.

This structured report is then passed to BGA (Blob Generation Agent) and our fuzzers.
Armed with a BIT, BGA and our fuzzers receive a confirmed, detailed blueprint for crafting a precise and effective exploit.

---

## ‚ú® The BCDA Difference: From Guesswork to Certainty

BCDA transforms the system from a heavy, resource-draining carpet-bombing approach into a 'strategic vulnerability discovery platform' that precisely targets high-probability vectors and concentrates resources where they matter most.

`MCGA (Finds Leads) ‚ûî BCDA (Verifies & Details Leads) ‚ûî BGA (Exploitation Leads)`

By filtering out false positives and enriching real vulnerabilities with precise trigger conditions, BCDA ensures that our most powerful and computationally expensive agent, BGA, focuses its efforts only on confirmed, high-value targets.
It is the crucial link that turns MCGA's broad surveillance into BGA's surgical strike, saving time and improving the quality of discovered bugs.

BCDA demonstrates that in automated security analysis, the goal isn't just to find more potential bugs‚Äîit's to find the *right* ones, armed with the intelligence needed to act on them.

## Dive Deeper

This was a look into our AI detective, BCDA.
To see how MLLA components work together, check out our other deep dives:

- [üåê **Browse the complete MLLA source code**](https://github.com/Team-Atlanta/aixcc-afc-atlantis/tree/main/example-crs-webservice/crs-multilang/blob-gen/multilang-llm-agent)
- [üèóÔ∏è **MLLA Overview: Teaching LLMs to Hunt Bugs Like Security Researchers**](https://team-atlanta.github.io/blog/post-mlla-overview/)
- [üó∫Ô∏è Deep dive into CPUA, MCGA, CGPA's code understanding and navigation](https://team-atlanta.github.io/blog/post-mlla-disc-agents/)
- [üõ†Ô∏è Deep dive into BGA's self-evolving exploits](https://team-atlanta.github.io/blog/post-mlla-bga/)
- [üß† **Context Engineering: How BGA Teaches LLMs to Write Exploits**](https://team-atlanta.github.io/blog/post-context-engineering/)

---
