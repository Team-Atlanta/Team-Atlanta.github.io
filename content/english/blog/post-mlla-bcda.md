---
title: "BCDA: The AI Detective Separating Real Bugs from False Alarms"
meta_title: ""
description: "A deep dive into BCDA, the AI agent that acts as a detective, analyzing potential vulnerability paths to distinguish genuine threats from false positives and creating detailed bug reports for exploitation."
date: 2025-08-28T11:00:00Z
image: "/images/blog/mlla/bcda_preview.png"
categories: ["Atlantis-Multilang"]
author: "Sangwoo Ji"
tags: ["mlla", "llm", "vulnerability-discovery", "static-analysis", "multi-agent", "bcda"]
draft: true
---

<!-- ## The Signal in the Noise

Every security researcher knows the feeling: you've got a promising lead‚Äîa dangerous function call, a suspicious data flow‚Äîbut it's buried in a mountain of similar, harmless code paths. Static analysis tools are notorious for generating thousands of "potential" vulnerabilities, leaving you with the monumental task of sifting through false positives to find the one genuine threat. It's not just tedious; it's where critical bugs get missed.

This is the exact problem we built the **Bug Candidate Detection Agent (BCDA)** to solve.

While other agents in our MLLA pipeline, like MCGA, are excellent at identifying suspicious neighborhoods in the codebase, BCDA is the detective we send in to knock on doors. It takes a potential vulnerability and asks the hard questions: Is this *actually* exploitable? If so, what precise sequence of events, what specific conditions, must be met to trigger it? It‚Äôs the critical step that transforms a vague "maybe" into an actionable "yes, right here." -->

---

## üéØ From Potential Sink to Actionable Intelligence

BCDA's core mission is to address the fundamental challenge of lightweight sink analysis: distinguishing real vulnerabilities from false-positive noise.
When our cartographer, MCGA, flags a function containing a potentially vulnerable "sink" (like a function that executes system commands), BCDA takes over.

Its job isn't just to say "yes" or "no."
BCDA performs a deep, multi-stage investigation powered by LLMs to produce a **Bug Inducing Thing (BIT)**.
A BIT is a high-fidelity, structured report detailing a confirmed vulnerability candidate.
It includes the exact location, the specific trigger conditions (like `if-else` branches), and a detailed analysis generated by LLMs.
This report becomes a detailed guid for our demolition expert, BGA, and fuzzing stages.

To get there, BCDA follows a rigorous four-step investigative process.


---
<!-- 
## Inside the Investigation: The BCDA Pipeline

BCDA‚Äôs process is methodical, designed to build a complete picture of a potential vulnerability, from gathering initial evidence to filing a comprehensive final report. -->

### Step 1: üîç Path Expansion and Pruning (Gathering the Evidence)

A simple call stack is like a list of locations a suspect visited; it tells you where they've been, but not what they did there or who else was involved.
It often misses crucial context from functions that aren't directly in the call chain, like utility or validation functions.

BCDA starts by **expanding the execution path**.
It receives the call path from the source (typically the harness) to the sink (detected by MCGA) and uses Tree-sitter-based parsing to identify *every single function call* made along that path.
It then provides this expanded universe of functions to an LLM.

But more data isn't always better.
To avoid analyzing irrelevant code, BCDA immediately follows up with **LLM-powered pruning**.
BCDA already has a lead from MCGA about the *type* of vulnerability it might be looking for (e.g., Command Injection, XXE, Path Traversal).
It asks the LLM, "Of all these functions, which ones are actually relevant to the the *type* of vulnerability?"
The LLM returns a list of only the necessary functions, giving BCDA a rich but focused context for its investigation.
This is like a detective interviewing dozens of people but quickly zeroing in on the handful of key witnesses.

### Step 2: üïµÔ∏è Vulnerability Classification (The Interrogation)

With the relevant code path established, BCDA begins its interrogation.
BCDA formulates a **sanitizer-specific prompt** for the LLM.
This isn't a generic question; it's a highly detailed briefing that includes:
* An explanation of the suspected vulnerability type.
* Common patterns and anti-patterns associated with it.
* Effective strategies for detecting it in code.

Armed with this domain knowledge and the expanded code path, the LLM analyzes the pruned code path and makes a definitive judgment: does this path contain the specified vulnerability, or is it a false alarm?

### Step 3: üîë Key Condition and Trigger Path Extraction (Reconstructing the Crime)

If the LLM confirms a vulnerability, BCDA‚Äôs most critical task begins: identifying the **key conditions** required to trigger it.
A bug is useless if you can't reach it.
BCDA needs to find the exact sequence of `if` statements, `try-catch` blocks, and other conditional logic that unlocks the path to the vulnerable code.

Instead of overwhelming the LLM with the entire path at once, BCDA analyzes it **transition by transition**.
It focuses on one function call at a time, asking the LLM: "To get from `function A` to `function B`, what conditions must be true?"

This granular, step-by-step approach allows the LLM to focus its analytical power, accurately identifying critical decision points.
For example, it might determine that an `if (user.isAdmin())` check must evaluate to `true` or that a `catch (Exception e)` block must be entered to reach the sink.

### Step 4: üìù BIT Generation (Filing the Case Report)

The investigation culminates in the creation of a **Bug Inducing Thing (BIT)**. 
This isn't just a simple alert; it's a structured data object optimized for the next stages of our pipeline.

Each BIT contains everything an exploitation agent needs to know:
* **Vulnerability Type:** The class of the bug (e.g., `COMMAND_INJECTION`).
* **Location:** The exact file path and line numbers.
* **Key Conditions:** A list of all branch conditions that must be satisfied.
* **Analysis Messages:** A log of the LLM's reasoning from each step.
* **Priority Level:** A score based on factors like how recently the code was changed.

This structured report is then passed to the BGA (Blob Generation Agent) and our fuzzers.
With a BIT in hand, BGA doesn't have to guess; it has a detailed, confirmed blueprint for crafting a precise and effective exploit.

---

## ‚ú® The BCDA Difference: From Guesswork to Certainty

BCDA elevates the system from heavy resource-consuming carpet boming system to a 'strategic vulnerability discovery platform' that precisely targets high-probability vectors and concentrates its resources on them.

`MCGA (Finds Leads) ‚ûî BCDA (Verifies & Details Leads) ‚ûî BGA (Exploits Verified Leads)`

By filtering false positives and enriching real vulnerabilities with precise trigger conditions, BCDA ensures that our most powerful and computationally expensive agent, BGA, focuses its efforts only on confirmed, high-value targets. 
It's the crucial link that turns MCGA's broad surveillance into BGA's surgical strike, saving immense time and dramatically increasing the quality of the bugs we find.

BCDA proves that in the world of automated security analysis, the goal isn't just to find more potential bugs‚Äîit's to find the right ones, with the right intelligence to act on them.

## Dive Deeper

This was a look into our AI detective, BCDA. 
To see how MLLA components work together, check out our other deep dives:

* [**MLLA Overview: Teaching LLMs to Hunt Bugs Like Security Researchers**](https://team-atlanta.github.io/blog/post-mlla-overview/)
* **üó∫Ô∏è Deep dive into CPUA, MCGA, CGPA's code understanding and navigation**
* **üõ†Ô∏è Deep dive into BGA's self-evolving exploits (will be release on Sep. 1st)**
* [**üåê Browse the complete MLLA source code**](https://github.com/Team-Atlanta/aixcc-afc-atlantis/tree/main/example-crs-webservice/crs-multilang/blob-gen/multilang-llm-agent)
```
