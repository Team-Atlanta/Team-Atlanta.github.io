<!doctype html><html itemscope lang=en-us itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=5"><meta name=theme-name content="hugoplate"><link rel="shortcut icon" href=/images/team-icon_hu_42d46689e5457328.png type=image/x-icon><link rel=icon href=/images/team-icon_hu_42d46689e5457328.png type=image/x-icon><link rel=icon type=image/png sizes=48x48 href=/images/team-icon_hu_fe460b572c629e4d.png><link rel=icon type=image/png sizes=96x96 href=/images/team-icon_hu_42d46689e5457328.png><link rel=apple-touch-icon sizes=144x144 href=/images/team-icon_hu_47fac973bbab3080.png><link rel=manifest href=/manifest.webmanifest><meta name=msapplication-TileColor content="#ddd"><meta name=theme-color content="#ffffff"><base href=https://team-atlanta.github.io/blog/post-custom-model/><title>Teaching LLMs to Retrieve: Custom Models for Security Patch Generation</title><meta name=keywords content="DARPA AIxCC,cybersecurity,fuzzing,LLM,AIxCC"><meta name=description content="How we trained specialized LLMs to learn what code context matters for vulnerability patching - moving from manual context engineering to adaptive code context learning through reinforcement learning"><meta property="og:image" content="https://team-atlanta.github.io/images/blog/custom-model/preview.png"><meta name=twitter:image content="https://team-atlanta.github.io/images/blog/custom-model/preview.png"><meta name=twitter:card content="summary_large_image"><meta property="og:image:width" content="1536"><meta property="og:image:height" content="1024"><meta property="og:image:type" content="image/.png"><meta property="og:title" content="Teaching LLMs to Retrieve: Custom Models for Security Patch Generation"><meta property="og:description" content="How we trained specialized LLMs to learn what code context matters for vulnerability patching - moving from manual context engineering to adaptive code context learning through reinforcement learning"><meta property="og:type" content="website"><meta property="og:url" content="https://team-atlanta.github.io/blog/post-custom-model/"><meta name=twitter:title content="Teaching LLMs to Retrieve: Custom Models for Security Patch Generation"><meta name=twitter:description content="How we trained specialized LLMs to learn what code context matters for vulnerability patching - moving from manual context engineering to adaptive code context learning through reinforcement learning"><script async src="https://www.googletagmanager.com/gtag/js?id=G-SKJZ8R4CQM"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-SKJZ8R4CQM")}</script><script>let indexURL="https://team-atlanta.github.io/searchindex.json",includeSectionsInSearch=["blog"],search_no_results="0 results for",search_initial_message=""</script><meta http-equiv=x-dns-prefetch-control content="on"><link rel=preconnect href=https://use.fontawesome.com crossorigin><link rel=preconnect href=//cdnjs.cloudflare.com><link rel=preconnect href=//www.googletagmanager.com><link rel=preconnect href=//www.google-analytics.com><link rel=dns-prefetch href=https://use.fontawesome.com><link rel=dns-prefetch href=//ajax.googleapis.com><link rel=dns-prefetch href=//cdnjs.cloudflare.com><link rel=dns-prefetch href=//www.googletagmanager.com><link rel=dns-prefetch href=//www.google-analytics.com><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//connect.facebook.net><link rel=dns-prefetch href=//platform.linkedin.com><link rel=dns-prefetch href=//platform.twitter.com><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Heebo:wght@400;600&family=Signika:wght@500;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script><link crossorigin=anonymous media=all rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><link href="/css/style.min.b1d8993d0e526cd09c1967ce69369985793bf2dedca1a05d22472421c056f4a7.css" integrity="sha256-sdiZPQ5SbNCcGWfOaTaZhXk78t7coaBdIkckIcBW9Kc=" rel=stylesheet><link defer async rel=stylesheet href="/css/style-lazy.min.da0b86e3fbde4973f5a052f06ca1e028c2f924f14a80a25c82c5478f128d0525.css" integrity="sha256-2guG4/veSXP1oFLwbKHgKML5JPFKgKJcgsVHjxKNBSU=" media=print onload='this.media="all",this.onload=null'></head><body><header class="header header-modern sticky top-0 z-30"><nav class="navbar container"><div class=order-0><a class="navbar-brand block" href=/>Team Atlanta</a></div><input id=nav-toggle type=checkbox class=hidden>
<label for=nav-toggle class="order-3 cursor-pointer flex items-center lg:hidden text-dark dark:text-white lg:order-1 p-2 rounded-lg hover:bg-theme-light dark:hover:bg-darkmode-theme-light transition-colors duration-300"><svg id="show-button" class="h-6 fill-current block transition-transform duration-300" viewBox="0 0 20 20"><title>Menu Open</title><path d="M0 3h20v2H0V3zm0 6h20v2H0V9zm0 6h20v2H0V0z"/></svg>
<svg id="hide-button" class="h-6 fill-current hidden transition-transform duration-300" viewBox="0 0 20 20"><title>Menu Close</title><polygon points="11 9 22 9 22 11 11 11 11 22 9 22 9 11 -2 11 -2 9 9 9 9 -2 11 -2" transform="rotate(45 10 10)"/></svg></label><ul id=nav-menu class="navbar-nav order-3 hidden lg:flex w-full pb-6 lg:order-1 lg:w-auto lg:space-x-2 lg:pb-0 xl:space-x-8"><li class=nav-item><a class="nav-link relative px-4 py-2 rounded-lg transition-all duration-300 hover:bg-theme-light dark:hover:bg-darkmode-theme-light focus-modern" href=/>Home</a></li><li class="nav-item nav-dropdown group relative"><a href=/authors/ class="nav-link
inline-flex items-center">AIxCC Team
<svg class="h-4 w-4 fill-current" viewBox="0 0 20 20"><path d="M9.293 12.95l.707.707L15.657 8l-1.414-1.414L10 10.828 5.757 6.586 4.343 8z"/></svg></a><ul class="nav-dropdown-list lg:group-hover:visible lg:group-hover:opacity-100"><li class=nav-dropdown-item><a class=nav-dropdown-link href=/authors/#team-leader>Team Leader</a></li><li class=nav-dropdown-item><a class=nav-dropdown-link href=/authors/#team-multilang>Atlantis-Multilang</a></li><li class=nav-dropdown-item><a class=nav-dropdown-link href=/authors/#team-c>Atlantis-C</a></li><li class=nav-dropdown-item><a class=nav-dropdown-link href=/authors/#team-java>Atlantis-Java</a></li><li class=nav-dropdown-item><a class=nav-dropdown-link href=/authors/#team-patch>Atlantis-Patch</a></li><li class=nav-dropdown-item><a class=nav-dropdown-link href=/authors/#team-sarif>Atlantis-SARIF</a></li><li class=nav-dropdown-item><a class=nav-dropdown-link href=/authors/#team-infra>Atlantis-Infra</a></li></ul></li><li class=nav-item><a class="nav-link relative px-4 py-2 rounded-lg transition-all duration-300 hover:bg-theme-light dark:hover:bg-darkmode-theme-light focus-modern" href=/artifacts/>Research & Code</a></li><li class=nav-item><a class="nav-link relative px-4 py-2 rounded-lg transition-all duration-300 hover:bg-theme-light dark:hover:bg-darkmode-theme-light focus-modern" href=/news/>News</a></li><li class=nav-item><a class="nav-link relative px-4 py-2 rounded-lg transition-all duration-300 hover:bg-theme-light dark:hover:bg-darkmode-theme-light focus-modern" href=/blog/>Blog</a></li></ul><div class="order-1 ml-auto flex items-center md:order-2 lg:ml-0"><button aria-label=search class="border-border text-dark hover:text-primary dark:border-darkmode-border mr-5 inline-block border-r pr-5 text-xl dark:text-white dark:hover:text-darkmode-primary p-2 rounded-lg hover:bg-theme-light dark:hover:bg-darkmode-theme-light transition-all duration-300 focus-modern" data-target=search-modal>
<i class="fa-solid fa-search"></i></button><div class="theme-switcher mr-5"><input id=theme-switcher data-theme-switcher type=checkbox>
<label for=theme-switcher><span class=sr-only>theme switcher</span>
<span><svg class="absolute left-[4px] top-[4px] z-10 opacity-100 dark:opacity-0" viewBox="0 0 56 56" fill="#fff" height="16" width="16"><path d="M30 4.6c0-1-.9-2-2-2a2 2 0 00-2 2v5c0 1 .9 2 2 2s2-1 2-2zm9.6 9a2 2 0 000 2.8c.8.8 2 .8 2.9.0L46 13a2 2 0 000-2.9 2 2 0 00-3 0zm-26 2.8c.7.8 2 .8 2.8.0.8-.7.8-2 0-2.9L13 10c-.7-.7-2-.8-2.9.0-.7.8-.7 2.1.0 3zM28 16A12 12 0 0016 28a12 12 0 0012 12 12 12 0 0012-12A12 12 0 0028 16zm23.3 14c1.1.0 2-.9 2-2s-.9-2-2-2h-4.9a2 2 0 00-2 2c0 1.1 1 2 2 2zM4.7 26a2 2 0 00-2 2c0 1.1.9 2 2 2h4.9c1 0 2-.9 2-2s-1-2-2-2zm37.8 13.6a2 2 0 00-3 0 2 2 0 000 2.9l3.6 3.5a2 2 0 002.9.0c.8-.8.8-2.1.0-3zM10 43.1a2 2 0 000 2.9c.8.7 2.1.8 3 0l3.4-3.5c.8-.8.8-2.1.0-2.9s-2-.8-2.9.0zm20 3.4c0-1.1-.9-2-2-2a2 2 0 00-2 2v4.9c0 1 .9 2 2 2s2-1 2-2z"/></svg>
<svg class="absolute left-[4px] top-[4px] z-10 opacity-0 dark:opacity-100" viewBox="0 0 24 24" fill="none" height="16" width="16"><path fill="#000" fill-rule="evenodd" clip-rule="evenodd" d="M8.2 2.2c1-.4 2 .6 1.6 1.5-1 3-.4 6.4 1.8 8.7a8.4 8.4.0 008.7 1.8c1-.3 2 .5 1.5 1.5v.1A10.3 10.3.0 0112.4 22 10.3 10.3.0 013.2 6.7c1-2 2.9-3.5 4.9-4.4z"/></svg></span></label></div><script>var themeSwitch,darkMode=!1;window.matchMedia("(prefers-color-scheme: dark)").matches&&(darkMode=!0),localStorage.getItem("theme")==="dark"?darkMode=!0:localStorage.getItem("theme")==="light"&&(darkMode=!1),darkMode&&document.documentElement.classList.toggle("dark"),themeSwitch=document.querySelectorAll("[data-theme-switcher]"),document.addEventListener("DOMContentLoaded",()=>{[].forEach.call(themeSwitch,function(e){e.checked=!!darkMode,e.addEventListener("click",()=>{document.documentElement.classList.toggle("dark"),localStorage.setItem("theme",document.documentElement.classList.contains("dark")?"dark":"light")})})})</script></div></nav></header><div class=search-modal aria-hidden=true style=--color-primary:#4a5d7a><div data-target=close-search-modal class=search-modal-overlay></div><div class=search-wrapper data-image=true data-description=true data-tags=true data-categories=true><div class=search-wrapper-header><label for=search-modal-input style=margin-top:-1px><span class=sr-only>search icon</span>
<svg viewBox="0 0 512 512" height="18" width="18" class="search-icon" data-type="search"><path fill="currentColor" d="M416 208c0 45.9-14.9 88.3-40 122.7L502.6 457.4c12.5 12.5 12.5 32.8.0 45.3s-32.8 12.5-45.3.0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9.0 208S93.1.0 208 0 416 93.1 416 208zM208 352a144 144 0 100-288 144 144 0 100 288z"/></svg>
<svg viewBox="0 0 512 512" height="18" width="18" class="search-reset" data-type="reset"><path fill="currentColor" d="M256 512A256 256 0 10256 0a256 256 0 100 512zM175 175c9.4-9.4 24.6-9.4 33.9.0l47 47 47-47c9.4-9.4 24.6-9.4 33.9.0s9.4 24.6.0 33.9l-47 47 47 47c9.4 9.4 9.4 24.6.0 33.9s-24.6 9.4-33.9.0l-47-47-47 47c-9.4 9.4-24.6 9.4-33.9.0s-9.4-24.6.0-33.9l47-47-47-47c-9.4-9.4-9.4-24.6.0-33.9z"/></svg>
</label><input id=search-modal-input type=text data-search-input autocomplete=off aria-label=Search placeholder="Search Post ..."></div><div class=search-wrapper-body><div class=search-result data-search-result></div><span class=search-result-empty></span></div><div class=search-wrapper-footer><span><kbd><svg width="14" height="14" fill="currentColor" viewBox="0 0 16 16"><path d="M3.204 11h9.592L8 5.519 3.204 11zm-.753-.659 4.796-5.48a1 1 0 011.506.0l4.796 5.48c.566.647.106 1.659-.753 1.659H3.204a1 1 0 01-.753-1.659z"/></svg>
</kbd><kbd><svg width="14" height="14" fill="currentColor" style="margin-top:1px" viewBox="0 0 16 16"><path d="M3.204 5h9.592L8 10.481 3.204 5zm-.753.659 4.796 5.48a1 1 0 001.506.0l4.796-5.48c.566-.647.106-1.659-.753-1.659H3.204a1 1 0 00-.753 1.659z"/></svg>
</kbd>to navigate
</span><span><kbd><svg width="12" height="12" fill="currentColor" style="display:inline-block" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M14.5 1.5a.5.5.0 01.5.5v4.8a2.5 2.5.0 01-2.5 2.5H2.707l3.347 3.346a.5.5.0 01-.708.708l-4.2-4.2a.5.5.0 010-.708l4-4a.5.5.0 11.708.708L2.707 8.3H12.5A1.5 1.5.0 0014 6.8V2a.5.5.0 01.5-.5z"/></svg>
</kbd>to select
</span><span class=search-result-info></span>
<span data-target=close-search-modal><kbd>ESC</kbd> to close</span></div></div></div><main><section class="section py-10 blog-single"><div class=container><div class="row justify-center"><article class=lg:col-10><div class=mb-10><picture><source srcset=/images/blog/custom-model/preview_hu_6b036da9e49dc515.webp media="(max-width: 575px)"><source srcset=/images/blog/custom-model/preview_hu_12f042785c581ea8.webp media="(max-width: 767px)"><source srcset=/images/blog/custom-model/preview_hu_f5cc79edeb77ccdc.webp media="(max-width: 991px)"><source srcset=/images/blog/custom-model/preview_hu_462d6cea21c63a37.webp><img loading=lazy decoding=async src=/images/blog/custom-model/preview_hu_d5664695654ab608.png class="w-full rounded img" alt="Teaching LLMs to Retrieve: Custom Models for Security Patch Generation" width=1536 height=1024></picture></div><h1 class="h2 mb-4">Teaching LLMs to Retrieve: Custom Models for Security Patch Generation</h1><ul class=mb-4><li class="mr-4 inline-block"><i class="fa-regular fa-user-group mr-2 text-primary"></i>
<a href=/authors/minjae-gwon/>Minjae Gwon</a>,
<a href=/authors/sangdon-park/>Sangdon Park</a></li><li class="mr-4 inline-block"><i class="fa-regular fa-folder mr-2"></i>
<a href=/categories/atlantis-patch/ class=ms-1>Atlantis patch</a></li><li class="mr-4 inline-block"><i class="fa-regular fa-clock mr-2"></i>
November 2, 2025</li></ul><div class="toc-container glass-card mb-6 p-4 rounded-lg"><h3 class="toc-title mb-3 text-lg font-semibold text-white flex items-center"><i class="fa-solid fa-list mr-2"></i>
Table of Contents
<button class="toc-toggle ml-auto text-sm" onclick=toggleTOC()>
<i class="fa-solid fa-chevron-up" id=toc-icon></i></button></h3><div class=toc-content id=toc-content><nav id=TableOfContents><ol><li><a href=#the-typedef-that-changed-everything>The Typedef That Changed Everything</a></li><li><a href=#from-engineering-to-learning>From Engineering to Learning</a></li><li><a href=#the-problem-context-windows-meet-reality>The Problem: Context Windows Meet Reality</a></li><li><a href=#code-context-learning-the-setup>Code Context Learning: The Setup</a></li><li><a href=#multi-turn-grpo-learning-from-success>Multi-Turn GRPO: Learning from Success</a></li><li><a href=#a-real-example-babynginxcpv-0>A Real Example: babynginx/cpv-0</a><ol><li><a href=#turn-1-fault-localization>Turn 1: Fault Localization</a></li><li><a href=#turn-2-expanding-context>Turn 2: Expanding Context</a></li><li><a href=#before-turn-3-the-critical-discovery>Before Turn 3: The Critical Discovery</a></li><li><a href=#the-generated-patch>The Generated Patch</a></li></ol></li><li><a href=#training-dynamics-what-actually-happens>Training Dynamics: What Actually Happens</a></li><li><a href=#results-does-it-actually-work>Results: Does It Actually Work?</a></li><li><a href=#aixcc-final-competition-real-world-performance>AIxCC Final Competition: Real-World Performance</a><ol><li><a href=#case-study-wireshark-ber-stack-buffer-overflow>Case Study: Wireshark BER Stack Buffer Overflow</a></li><li><a href=#why-this-patch-is-sound>Why This Patch is Sound</a></li><li><a href=#what-this-demonstrates>What This Demonstrates</a></li></ol></li><li><a href=#key-findings-and-contributions>Key Findings and Contributions</a></li><li><a href=#contributions-to-the-field>Contributions to the Field</a></li><li><a href=#limitations-and-future-directions>Limitations and Future Directions</a><ol><li><a href=#future-research-opportunities>Future Research Opportunities</a></li></ol></li><li><a href=#what-this-means-for-security>What This Means for Security</a></li></ol></nav></div></div><script>function toggleTOC(){const e=document.getElementById("toc-content"),t=document.getElementById("toc-icon");e.classList.contains("collapsed")?(e.classList.remove("collapsed"),t.classList.remove("fa-chevron-down"),t.classList.add("fa-chevron-up"),e.style.maxHeight=e.scrollHeight+"px"):(e.classList.add("collapsed"),t.classList.remove("fa-chevron-up"),t.classList.add("fa-chevron-down"),e.style.maxHeight="0px")}document.addEventListener("DOMContentLoaded",function(){const e=document.getElementById("toc-content");e&&(e.style.maxHeight=e.scrollHeight+"px"),initializeBackToTop()});function initializeBackToTop(){const e=document.getElementById("back-to-top");if(!e)return;window.addEventListener("scroll",function(){window.pageYOffset>300?e.classList.remove("hidden"):e.classList.add("hidden")}),e.addEventListener("click",function(){window.scrollTo({top:0,behavior:"smooth"})})}</script><div class="fixed bottom-8 right-8 z-50"><button id=back-to-top class="hidden bg-primary text-white w-14 h-14 rounded-full shadow-lg hover:shadow-xl transition-all duration-300 transform hover:scale-110 focus:outline-none focus:ring-2 focus:ring-primary focus:ring-offset-2" aria-label="Back to top">
<i class="fa-solid fa-arrow-up"></i></button></div><div class="content mb-10"><h2 id=the-typedef-that-changed-everything>The Typedef That Changed Everything</h2><p>Picture this: you&rsquo;re asking an LLM to patch a security vulnerability in Nginx, a codebase with millions of lines. The bug is clear, the fix location is obvious, but your patch won&rsquo;t compile. Why? Because buried somewhere in the headers are two critical <code>typedef</code> definitions that the LLM never saw.</p><p>We discovered this the hard way during the AIxCC Semifinals. Challenge <code>challenge-004-nginx-cp/cpv15</code> became our wake-up call. When we ran our baseline patching agent Aider 20 times without the typedef definitions, only 5 patches compiled successfully. But when we included those typedefs? 18 out of 20 compiled successfully. <strong>That 5/20 → 18/20 leap wasn&rsquo;t about smarter LLMs or better prompts. It was about giving the right context.</strong></p><p>This insight inspired the design of our agents (e.g., the Multi-turn Retrieval Agent) and a deeper question: instead of hand-crafting context, could we teach an LLM to <strong>learn</strong> what context really matters on its own?</p><h2 id=from-engineering-to-learning>From Engineering to Learning</h2><p>Context engineering works—as we showed in our <a href=https://team-atlanta.github.io/blog/post-context-engineering/ target=_blank>previous post</a>, systematic information structuring dramatically improves LLM performance. But context engineering has a problem: it&rsquo;s manual, heuristic-driven, and doesn&rsquo;t scale across different bug types and codebases.</p><p>Human developers don&rsquo;t patch bugs in one shot. They form hypotheses, examine code, run tests, gather clues, refine their search. They <strong>learn</strong> what context matters through iteration. Why shouldn&rsquo;t our AI do the same?</p><p>This insight led us to develop <strong>custom models for code context learning</strong>—specialized LLMs trained through reinforcement learning to identify and retrieve the missing pieces needed for successful patch generation.</p><h2 id=the-problem-context-windows-meet-reality>The Problem: Context Windows Meet Reality</h2><p>Let&rsquo;s be brutally honest about the challenges:</p><ul><li><strong>Context Window Limitations</strong>: Even with today&rsquo;s long-context models, you can&rsquo;t feed an entire large-scale codebase into an LLM. The attention complexity and window size limits make it infeasible. A typical enterprise codebase might have 10 million lines—good luck fitting that into a 200K token context window.</li><li><strong>API Costs</strong>: Processing massive inputs isn&rsquo;t just technically difficult—it&rsquo;s financially prohibitive. Repeatedly sending thousands of lines to GPT-4 or Claude for every patching attempt would bankrupt most security budgets faster than you can say &ldquo;vulnerability.&rdquo;</li><li><strong>The Missing Context Problem</strong>: But here&rsquo;s the real challenge—you need <em>just enough</em> context for the patch to work, but not so much that you overwhelm the model or your wallet. Too little context and your patch won&rsquo;t compile. Too much and you waste tokens on irrelevant code.</li></ul><p>How do we find that sweet spot? We treat it as a learning problem.</p><h2 id=code-context-learning-the-setup>Code Context Learning: The Setup</h2><figure class=img-center role=group aria-describedby="caption-Overview of custom model for code context learning"><img title loading=lazy decoding=async class="img img-fluid" width=5760 height=3300 src=/images/blog/custom-model/overview_hu_808e0d93848e9109.webp alt onerror='this.onerror="null",this.src="/images/blog/custom-model/overview_hu_419d33844fb5e0ed.png"'><figcaption id="caption-Overview of custom model for code context learning" class=caption-Overview-of-custom-model-for-code-context-learning>Overview of custom model for code context learning</figcaption></figure><script>window.addEventListener("load",e=>{const t=GLightbox()})</script><p>We formulated code context learning as a reinforcement learning (RL) problem. Here&rsquo;s the intuition:</p><ul><li><strong>The Environment</strong>: A codebase with a vulnerability and a crash log</li><li><strong>The Agent</strong>: Our custom LLM that decides what code to retrieve</li><li><strong>The Actions</strong>: Retrieving specific code symbols (functions, structs, types)</li><li><strong>The Reward</strong>: Whether the generated patch compiles and fixes the vulnerability</li></ul><p>At each turn $h$, the agent observes the current context $x_{t,h}$ and chooses retrieval actions $a_{t,h}$—requests to fetch specific code definitions. The environment integrates these retrieved artifacts into the context, constructing the next state $x_{t,h+1}$.</p><p>After $H$ turns of retrieval, we feed the final context to a powerful general-purpose LLM (GPT-4, Claude, Gemini) for actual patch generation. This architecture deliberately <strong>decouples context acquisition from patch generation</strong>, letting us leverage state-of-the-art LLMs while maintaining precise control over what information they receive.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plaintext data-lang=plaintext><span style=display:flex><span>┌─────────────┐
</span></span><span style=display:flex><span>│ Crash Log   │
</span></span><span style=display:flex><span>│ + Metadata  │
</span></span><span style=display:flex><span>└──────┬──────┘
</span></span><span style=display:flex><span>       │
</span></span><span style=display:flex><span>       ▼
</span></span><span style=display:flex><span>┌─────────────────────┐
</span></span><span style=display:flex><span>│ Retrieval Policy π  │◄─── Custom Model (Llama-3.2-3B)
</span></span><span style=display:flex><span>│ &#34;What should I      │
</span></span><span style=display:flex><span>│  retrieve next?&#34;    │
</span></span><span style=display:flex><span>└──────┬──────────────┘
</span></span><span style=display:flex><span>       │
</span></span><span style=display:flex><span>       │ Actions: retrieve ngx_http_userid_ctx_t,
</span></span><span style=display:flex><span>       │          retrieve NGX_CUSTOM_FEATURE__NR, ...
</span></span><span style=display:flex><span>       ▼
</span></span><span style=display:flex><span>┌──────────────────────┐
</span></span><span style=display:flex><span>│ Environment          │
</span></span><span style=display:flex><span>│ (Code Context        │
</span></span><span style=display:flex><span>│  Builder)            │
</span></span><span style=display:flex><span>└──────┬───────────────┘
</span></span><span style=display:flex><span>       │
</span></span><span style=display:flex><span>       │ Updated context with retrieved symbols
</span></span><span style=display:flex><span>       ▼
</span></span><span style=display:flex><span>   Repeat for H turns
</span></span><span style=display:flex><span>       │
</span></span><span style=display:flex><span>       ▼
</span></span><span style=display:flex><span>┌──────────────────────┐
</span></span><span style=display:flex><span>│ Patch Generation LLM │◄─── GPT-4 / Claude / Gemini
</span></span><span style=display:flex><span>│ (with full context)  │
</span></span><span style=display:flex><span>└──────┬───────────────┘
</span></span><span style=display:flex><span>       │
</span></span><span style=display:flex><span>       ▼
</span></span><span style=display:flex><span>  Generated Patch
</span></span></code></pre></div><p>The key insight: <strong>smaller specialized models can learn effective retrieval strategies through task-specific training, reducing the need for expensive general-purpose models to do everything.</strong></p><h2 id=multi-turn-grpo-learning-from-success>Multi-Turn GRPO: Learning from Success</h2><figure class=img-center role=group aria-describedby="caption-Adapted and re-colored from the original Hugging Face diagram"><img title loading=lazy decoding=async class="img img-fluid" width=6001 height=1861 src=/images/blog/custom-model/multi-turn-grpo_hu_e7d9ad286f70522a.webp alt onerror='this.onerror="null",this.src="/images/blog/custom-model/multi-turn-grpo_hu_5e5ad11534fcebbd.png"'><figcaption id="caption-Adapted and re-colored from the original Hugging Face diagram" class=caption-Adapted-and-re-colored-from-the-original-Hugging-Face-diagram>Adapted and re-colored from the original Hugging Face diagram</figcaption></figure><p>We train our retrieval policy using Group Relative Policy Optimization (GRPO), adapted for multi-turn retrieval. The training process involves:</p><p><strong>1. Reward Modeling</strong>: Two components guide learning:</p><ul><li><strong>Format reward</strong> ($R_{\mathrm{fmt}}$): Ensures structurally correct retrieval actions (valid markdown, proper symbol identification)</li><li><strong>Soundness reward</strong> ($R_{\mathrm{snd}}$): Assesses whether the final patch compiles, preserves functionality, and fixes the vulnerability</li></ul><p><strong>2. Multi-Turn Trajectory Optimization</strong>: Unlike standard single-turn GRPO, our agent generates trajectories of retrieval actions over multiple turns. Each turn builds on previous retrievals, gradually constructing the context needed for successful patching.</p><p><strong>3. Online Learning</strong>: Rather than training on all challenge project vulnerabilities (CPVs) simultaneously—which would be memory-intensive—we update the policy online. The agent concentrates on a single CPV repeatedly until reaching a success plateau, then advances to the next. This mirrors how developers work: deep focus on one problem before moving to the next.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Simplified training objective (multi-turn GRPO)</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> cpv <span style=color:#f92672>in</span> challenge_project_vulnerabilities:
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> turn <span style=color:#f92672>in</span> range(H):  <span style=color:#75715e># H retrieval turns</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># Generate retrieval actions</span>
</span></span><span style=display:flex><span>        actions <span style=color:#f92672>=</span> policy(context)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># Execute retrieval, update context</span>
</span></span><span style=display:flex><span>        context <span style=color:#f92672>=</span> environment<span style=color:#f92672>.</span>retrieve(actions)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># Compute rewards (format + soundness)</span>
</span></span><span style=display:flex><span>        reward <span style=color:#f92672>=</span> compute_reward(actions, context)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># Update policy based on reward</span>
</span></span><span style=display:flex><span>        policy<span style=color:#f92672>.</span>update(reward, keep_close_to_reference_policy)
</span></span></code></pre></div><p>The magic happens in that last line: the policy learns which symbols are worth retrieving by directly optimizing for patch success.</p><h2 id=a-real-example-babynginxcpv-0>A Real Example: babynginx/cpv-0</h2><p>Let&rsquo;s walk through how the learned policy works in practice. We&rsquo;ll use <code>babynginx/cpv-0</code>, an internal benchmark motivated by CVE-2022-0995 (an out-of-bounds access in the Linux kernel), adapted to a simplified Nginx setting.</p><p><strong>The Bug</strong>: The vulnerability arises when parsing a custom request header <code>X-Feature</code>. A numeric value gets converted using <code>ngx_atoi</code> and used to set a bitmap index. The range check incorrectly uses <code>sizeof(bitmap) * BITS_PER_LONG</code>, permitting out-of-bounds access.</p><h3 id=turn-1-fault-localization>Turn 1: Fault Localization</h3><p>The process begins with an AddressSanitizer report indicating the failure site:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=display:flex><span><span style=color:#f92672>==</span><span style=color:#ae81ff>1234</span><span style=color:#f92672>==</span>ERROR: AddressSanitizer: heap<span style=color:#f92672>-</span>buffer<span style=color:#f92672>-</span>overflow
</span></span><span style=display:flex><span>    <span style=color:#75715e>#0 0x7f8b4c in ngx_http_process_custom_features /nginx/src/http/ngx_http_custom.c:156
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#75715e>#1 0x7f8b2a in ngx_http_process_request /nginx/src/http/ngx_http_request.c:2891
</span></span></span></code></pre></div><p><strong>Retrieved Action</strong> (with reasoning from the model):</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-markdown data-lang=markdown><span style=display:flex><span>The potential vulnerability is an out-of-bounds read error in the <span style=color:#e6db74>`ngx_http_process_custom_features`</span> function. The crash occurs at line 156 when processing custom features.
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span> <span style=font-weight:700>**Relevant Symbols:**</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>1.</span> <span style=color:#e6db74>`ngx_http_process_custom_features`</span>
</span></span></code></pre></div><p>Without this initial localization, subsequent retrievals would lack direction. The model learns that crash stack traces point to critical functions.</p><h3 id=turn-2-expanding-context>Turn 2: Expanding Context</h3><p>At this stage, partial context has been assembled, but crucial information about valid feature indices is missing.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=display:flex><span><span style=color:#75715e>// Augmented Code Context
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>[<span style=color:#ae81ff>148</span>]<span style=color:#f92672>:</span> <span style=color:#66d9ef>static</span> <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>ngx_http_process_custom_features</span>(<span style=color:#66d9ef>ngx_http_request_t</span> <span style=color:#f92672>*</span>r) {
</span></span><span style=display:flex><span>[<span style=color:#ae81ff>149</span>]<span style=color:#f92672>:</span>     <span style=color:#66d9ef>ngx_int_t</span> feature_id;
</span></span><span style=display:flex><span>[<span style=color:#ae81ff>150</span>]<span style=color:#f92672>:</span>     feature_id <span style=color:#f92672>=</span> <span style=color:#a6e22e>ngx_atoi</span>(r<span style=color:#f92672>-&gt;</span>headers_in<span style=color:#f92672>-&gt;</span>x_feature<span style=color:#f92672>-&gt;</span>value.data,
</span></span><span style=display:flex><span>[<span style=color:#ae81ff>151</span>]<span style=color:#f92672>:</span>                           r<span style=color:#f92672>-&gt;</span>headers_in<span style=color:#f92672>-&gt;</span>x_feature<span style=color:#f92672>-&gt;</span>value.len);
</span></span><span style=display:flex><span>[<span style=color:#ae81ff>152</span>]<span style=color:#f92672>:</span>
</span></span><span style=display:flex><span>[<span style=color:#ae81ff>153</span>]<span style=color:#f92672>:</span>     <span style=color:#75715e>// BUG: incorrect bound check
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>[<span style=color:#ae81ff>154</span>]<span style=color:#f92672>:</span>     <span style=color:#66d9ef>if</span> (feature_id <span style=color:#f92672>&gt;=</span> <span style=color:#ae81ff>0</span> <span style=color:#f92672>&amp;&amp;</span>
</span></span><span style=display:flex><span>[<span style=color:#ae81ff>155</span>]<span style=color:#f92672>:</span>         feature_id <span style=color:#f92672>&lt;</span> <span style=color:#66d9ef>sizeof</span>(r<span style=color:#f92672>-&gt;</span>http_features<span style=color:#f92672>-&gt;</span>bitmap) <span style=color:#f92672>*</span> BITS_PER_LONG) {
</span></span><span style=display:flex><span>[<span style=color:#ae81ff>156</span>]<span style=color:#f92672>:</span>         <span style=color:#a6e22e>ngx_set_bit</span>(r<span style=color:#f92672>-&gt;</span>http_features<span style=color:#f92672>-&gt;</span>bitmap, feature_id);  <span style=color:#75715e>// @BUG_HERE
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>[<span style=color:#ae81ff>157</span>]<span style=color:#f92672>:</span>     }
</span></span><span style=display:flex><span>[<span style=color:#ae81ff>158</span>]<span style=color:#f92672>:</span> }
</span></span></code></pre></div><p><strong>Retrieved Action</strong>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-markdown data-lang=markdown><span style=display:flex><span>The following symbols are relevant to the provided C code snippet:
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span> <span style=font-weight:700>**Relevant Symbols:**</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span> <span style=color:#66d9ef>1.</span> <span style=color:#e6db74>`ngx_http_features_t`</span> (structure definition)
</span></span><span style=display:flex><span> <span style=color:#66d9ef>2.</span> <span style=color:#e6db74>`NGX_CUSTOM_FEATURE__NR`</span> (boundary constant)
</span></span></code></pre></div><p>The model has learned that structure definitions and boundary constants are critical for understanding buffer limits.</p><h3 id=before-turn-3-the-critical-discovery>Before Turn 3: The Critical Discovery</h3><p>The context builder retrieves the header file, uncovering the missing structure:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=display:flex><span><span style=color:#75715e>// Augmented Code Context
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>typedef</span> <span style=color:#66d9ef>struct</span> {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>unsigned</span> <span style=color:#66d9ef>long</span> bitmap[<span style=color:#ae81ff>2</span>];
</span></span><span style=display:flex><span>} <span style=color:#66d9ef>ngx_http_features_t</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#define NGX_CUSTOM_FEATURE__NR  64
</span></span></span></code></pre></div><p><strong>This discovery is decisive.</strong> The macro <code>NGX_CUSTOM_FEATURE__NR</code> specifies the upper bound of valid feature indices. Our empirical evaluation showed that without retrieving this symbol, LLM-generated patches consistently failed—either uncompilable or logically unsound.</p><h3 id=the-generated-patch>The Generated Patch</h3><p>With complete context, the patching LLM generates:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-diff data-lang=diff><span style=display:flex><span><span style=color:#f92672>--- a/src/http/ngx_http_custom.c
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+++ b/src/http/ngx_http_custom.c
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span><span style=color:#75715e>@@ -152,7 +152,7 @@ static void ngx_http_process_custom_features(ngx_http_request_t *r) {
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>                           r-&gt;headers_in-&gt;x_feature-&gt;value.len);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>-    if (feature_id &gt;= 0 &amp;&amp;
</span></span></span><span style=display:flex><span><span style=color:#f92672>-        feature_id &lt; sizeof(r-&gt;http_features-&gt;bitmap) * BITS_PER_LONG) {
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+    if (feature_id &gt;= 0 &amp;&amp; feature_id &lt; NGX_CUSTOM_FEATURE__NR) {
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span>         ngx_set_bit(r-&gt;http_features-&gt;bitmap, feature_id);
</span></span><span style=display:flex><span>     }
</span></span><span style=display:flex><span> }
</span></span></code></pre></div><p>The key improvement: replacing a brittle size-based bound with a semantically correct check against <code>NGX_CUSTOM_FEATURE__NR</code>. This ensures both memory safety and logical correctness.</p><h2 id=training-dynamics-what-actually-happens>Training Dynamics: What Actually Happens</h2><p>We fine-tuned a custom model based on Meta&rsquo;s Llama-3.2-3B-Instruct on 7 CPV instances, training on 8× NVIDIA A100 (80GB) GPUs. The hyperparameters were optimized for code retrieval:</p><ul><li><strong>Context Window</strong>: 8,192 tokens max prompt, 10,240 total sequence length</li><li><strong>Parameter-Efficient Fine-Tuning</strong>: LoRA with rank 32 and alpha 32</li><li><strong>Optimization</strong>: AdamW with learning rate $5 \times 10^{-6}$</li><li><strong>GRPO Group Size</strong>: 12 parallel generations per step</li><li><strong>Retrieval Turns</strong>: $H = 4$ steps per episode</li><li><strong>Downstream Evaluation</strong>: GPT-4.1 for patch generation</li></ul><p>The training trajectories reveal fascinating patterns:</p><ul><li><strong>Early Sparse Successes</strong>: In many CPVs, the maximum reward spikes to 1.0 well before the mean reward rises. This confirms the utility of group-based optimization—even when the policy is immature, diversity in rollouts can surface a correct retrieval path.</li><li><strong>Staircase-like Improvement</strong>: Mean reward increases in discrete jumps rather than smoothly. This reflects the sequential nature of retrieval: once the policy learns to fetch a critical symbol, downstream steps become substantially easier.</li><li><strong>Project-Dependent Difficulty</strong>: Some projects show long flat regions with zero reward, while others exhibit frequent reward spikes. This suggests varying difficulty in context localization across different codebases.</li><li><strong>Persistence Matters</strong>: The recurrence of max-reward spikes across epochs indicates that repeated attempts in our online learning don&rsquo;t merely overfit—they stabilize the policy so success can be rediscovered consistently.</li></ul><h2 id=results-does-it-actually-work>Results: Does It Actually Work?</h2><p>We evaluated our custom model on 18 CPVs across three checkpoints (rc1, rc2, rc3). Here&rsquo;s the breakdown:</p><table><thead><tr><th>Success Rate</th><th>Checkpoint 1</th><th>Checkpoint 2</th><th>Checkpoint 3</th></tr></thead><tbody><tr><td><strong>Sound Patches</strong></td><td>9/18 (50%)</td><td>11/18 (61%)</td><td>10/18 (56%)</td></tr></tbody></table><p><strong>Key Insights</strong>:</p><ul><li><strong>Overall performance</strong>: Roughly half of all patch attempts succeeded, demonstrating the agent can generate compilable fixes across diverse bug types</li><li><strong>Checkpoint progression</strong>: Later checkpoints showed fewer severe failures, suggesting moderate improvements over initial training</li><li><strong>Consistent failures</strong>: Certain CPVs (e.g., <code>freerdp-1</code>, <code>freerdp-2</code>, <code>libpng-1</code>) failed across all checkpoints—indicating bug classes that remain difficult</li><li><strong>Reliable successes</strong>: Other CPVs (e.g., <code>integration-test-1/2</code>, <code>libexif-1/2</code>, <code>libxml2-1</code>, <code>sqlite3-5</code>) succeeded consistently, showing sufficient retrieval context for these categories</li></ul><h2 id=aixcc-final-competition-real-world-performance>AIxCC Final Competition: Real-World Performance</h2><p>The true test came at the DARPA AIxCC Final Competition, where our custom model-powered agent faced real-world vulnerabilities under competitive conditions. Here&rsquo;s a concrete example of how our approach performed in the high-stakes finals.</p><h3 id=case-study-wireshark-ber-stack-buffer-overflow>Case Study: Wireshark BER Stack Buffer Overflow</h3><p><strong>The Challenge</strong>: A stack-buffer-overflow vulnerability in Wireshark&rsquo;s BER (Basic Encoding Rules) dissector—specifically in the <code>dissect_ber_GeneralString</code> function. This is exactly the kind of complex, real-world vulnerability that tests whether AI-assisted patching actually works.</p><p><strong>The Crash Log</strong>: Our agent received this AddressSanitizer report:</p><pre tabindex=0><code>==ERROR: AddressSanitizer: stack-buffer-overflow on address 0x7fff501517bd
at pc 0x000005431adb bp 0x7fff50151670 sp 0x7fff50151668
WRITE of size 1 at 0x7fff501517bd thread T0
SCARINESS: 46 (1-byte-write-stack-buffer-overflow)
    #0 0x5431ada in dissect_ber_GeneralString /src/wireshark/epan/dissectors/packet-ber.c:3194:34
    #1 0x542899b in try_dissect_unknown_ber /src/wireshark/epan/dissectors/packet-ber.c:935:26
    #2 0x5b84ecd in call_dissector_through_handle /src/wireshark/epan/packet.c:887:9
    ...

Address 0x7fff501517bd is located in stack of thread T0 at offset 93 in frame
    #0 0x5427a1f in try_dissect_unknown_ber /src/wireshark/epan/dissectors/packet-ber.c:814

  This frame has 12 object(s):
    [32, 40) &#39;val.i510&#39; (line 2021)
    [64, 72) &#39;val.i&#39; (line 2021)
    [96, 97) &#39;ber_class&#39; (line 816) &lt;== Memory access at offset 93 underflows this variable
    ...
</code></pre><p><strong>The Complexity</strong>: This bug involves:</p><ul><li>Stack memory layout with precise bounds</li><li>Multiple function calls through dissector handlers</li><li>Buffer size management across different code paths</li><li>Complex interaction between <code>name_string</code>, <code>max_len</code>, and actual buffer capacity</li></ul><p><strong>The Generated Patch</strong>: Our custom model-powered agent successfully identified the vulnerable code and generated this sound patch:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-diff data-lang=diff><span style=display:flex><span>diff --git a/epan/dissectors/packet-ber.c b/epan/dissectors/packet-ber.c
</span></span><span style=display:flex><span>index ce97968..42ba5c2 100644
</span></span><span style=display:flex><span><span style=color:#f92672>--- a/epan/dissectors/packet-ber.c
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+++ b/epan/dissectors/packet-ber.c
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span><span style=color:#75715e>@@ -3054,8 +3054,8 @@ dissect_ber_GeneralString(asn1_ctx_t *actx, proto_tree *tree, tvbuff_t *tvb, int
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>     proto_item *cause;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>     str = str_arr;
</span></span><span style=display:flex><span><span style=color:#f92672>-    max_len = 255;
</span></span></span><span style=display:flex><span><span style=color:#f92672>-    if (name_string) {
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+    max_len = sizeof(str_arr);
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+    if (name_string &amp;&amp; name_len &gt; 0) {
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span>         str = name_string;
</span></span><span style=display:flex><span>         max_len = name_len;
</span></span><span style=display:flex><span>     }
</span></span><span style=display:flex><span><span style=color:#75715e>@@ -3086,12 +3086,17 @@ dissect_ber_GeneralString(asn1_ctx_t *actx, proto_tree *tree, tvbuff_t *tvb, int
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>         return end_offset;
</span></span><span style=display:flex><span>     }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>+    /* Ensure we do not write out of bounds; always leave space for NUL. */
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span>     if (len &gt;= (max_len - 1)) {
</span></span><span style=display:flex><span><span style=color:#f92672>-        len = max_len - 1;
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+        len = max_len &gt; 0 ? max_len - 1 : 0;
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+    }
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+    /* If buffer for output is 0, skip copy */
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+    if (max_len &gt; 0 &amp;&amp; len &gt; 0) {
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+        tvb_memcpy(tvb, str, offset, len);
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+        str[len] = 0;
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+    } else if (max_len &gt; 0) {
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+        str[0] = 0;
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span>     }
</span></span><span style=display:flex><span><span style=color:#f92672>-
</span></span></span><span style=display:flex><span><span style=color:#f92672>-    tvb_memcpy(tvb, str, offset, len);
</span></span></span><span style=display:flex><span><span style=color:#f92672>-    str[len]=0;
</span></span></span><span style=display:flex><span><span style=color:#f92672></span>
</span></span><span style=display:flex><span>     if (hf_id &gt; 0) {
</span></span><span style=display:flex><span>         proto_tree_add_string(tree, hf_id, tvb, offset, len, str);
</span></span><span style=display:flex><span><span style=color:#75715e>@@ -3178,7 +3183,7 @@ dissect_ber_GeneralString(asn1_ctx_t *actx, proto_tree *tree, tvbuff_t *tvb, int
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span>     offset = dissect_ber_restricted_string(false, BER_UNI_TAG_GeneralString, actx, tree, tvb, offset, hf_id, (name_string) ? &amp;out_tvb : NULL);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>-    if (name_string) {
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+    if (name_string &amp;&amp; name_len &gt; 0) {
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span>         /*
</span></span><span style=display:flex><span>          * XXX - do we want to just get what&#39;s left in the tvbuff
</span></span><span style=display:flex><span>          * if the full length isn&#39;t available in the tvbuff, or
</span></span><span style=display:flex><span><span style=color:#75715e>@@ -3186,12 +3191,12 @@ dissect_ber_GeneralString(asn1_ctx_t *actx, proto_tree *tree, tvbuff_t *tvb, int
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>          */
</span></span><span style=display:flex><span>         if (out_tvb) {
</span></span><span style=display:flex><span>             tvb_len = tvb_get_uint8(tvb, offset);
</span></span><span style=display:flex><span><span style=color:#f92672>-            if ((unsigned)tvb_len &gt;= name_len) {
</span></span></span><span style=display:flex><span><span style=color:#f92672>-                tvb_memcpy(out_tvb, (uint8_t*)name_string, 0, name_len-1);
</span></span></span><span style=display:flex><span><span style=color:#f92672>-            } else {
</span></span></span><span style=display:flex><span><span style=color:#f92672>-                tvb_memcpy(out_tvb, (uint8_t*)name_string, 0, tvb_len);
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+            /* Clamp copy len to fit inside output buffer */
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+            unsigned copy_len = ((unsigned)tvb_len &lt; (name_len - 1)) ? (unsigned)tvb_len : (name_len - 1);
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+            if (copy_len &gt; 0) {
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+                tvb_memcpy(out_tvb, (uint8_t*)name_string, 0, copy_len);
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span>             }
</span></span><span style=display:flex><span><span style=color:#f92672>-            name_string[tvb_len] = &#39;\0&#39;;
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+            name_string[copy_len] = &#39;\0&#39;;
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span>         }
</span></span><span style=display:flex><span>     }
</span></span></code></pre></div><h3 id=why-this-patch-is-sound>Why This Patch is Sound</h3><p>The generated patch demonstrates sophisticated understanding of the vulnerability:</p><ol><li><strong>Correct Buffer Size Calculation</strong>: Changed from hardcoded <code>max_len = 255</code> to <code>max_len = sizeof(str_arr)</code>, ensuring the size matches actual buffer allocation.</li><li><strong>Defensive Null Checks</strong>: Added <code>name_len > 0</code> validation in multiple places to prevent zero-length buffer operations that could cause underflows.</li><li><strong>Safe Length Clamping</strong>: Implemented proper bounds checking with <code>len = max_len > 0 ? max_len - 1 : 0</code> to handle edge cases where <code>max_len</code> might be zero.</li><li><strong>Conditional Memory Operations</strong>: Wrapped <code>tvb_memcpy</code> calls in guards checking both <code>max_len > 0</code> and <code>len > 0</code>, preventing out-of-bounds writes entirely.</li><li><strong>Improved Copy Length Logic</strong>: In the second location, replaced conditional logic with a single clamped <code>copy_len</code> calculation, making the bounds checking explicit and auditable.</li></ol><h3 id=what-this-demonstrates>What This Demonstrates</h3><p>This real-world example validates several key aspects of our approach:</p><ul><li><strong>Context Learning in Action</strong>: The model successfully retrieved and utilized context about buffer structures, size constraints, and calling patterns to generate a comprehensive fix addressing multiple vulnerable code paths.</li><li><strong>Security-Aware Patching</strong>: The patch doesn&rsquo;t just stop the crash—it implements defense-in-depth by adding multiple layers of validation, showing the model learned security principles beyond simple syntax fixes.</li><li><strong>Production-Ready Quality</strong>: The generated code includes appropriate comments, maintains code style consistency, and handles edge cases that human reviewers would expect in a professional security patch.</li><li><strong>Competition Performance</strong>: This success in the high-pressure AIxCC Finals environment demonstrates that learned retrieval policies can generalize to unseen vulnerabilities in real-world, large-scale codebases like Wireshark.</li></ul><h2 id=key-findings-and-contributions>Key Findings and Contributions</h2><p>After developing and evaluating custom models for patching, here&rsquo;s what we learned:</p><ul><li><strong>✅ With proper code context, commercial LLMs generate secure patches</strong>: When provided comprehensive and relevant code context through multi-turn retrieval, state-of-the-art commercial models demonstrate strong capability in producing functionally correct and security-compliant patches.</li><li><strong>✅ Pretrained models have fair baseline performance</strong>: Base models like Llama-3.2-3B-Instruct exhibit reasonable baseline performance in identifying relevant code artifacts, providing a solid foundation for specialization.</li><li><strong>✅ RL fine-tuning improves context selection</strong>: Reinforcement learning using multi-turn GRPO significantly enhances the model&rsquo;s ability to select optimal code contexts, leading to measurable improvements in patch generation quality.</li><li><strong>⚠️ Forgetting remains a challenge</strong>: Online learning introduces catastrophic forgetting—knowledge from earlier CPVs degrades when adapting to new instances, limiting overall training effectiveness.</li></ul><h2 id=contributions-to-the-field>Contributions to the Field</h2><p>This work makes several key contributions to AI-assisted security patch generation:</p><ol><li><strong>Empirical Validation of Context Importance</strong>: We demonstrate that providing missing code context (e.g., undefined symbol definitions) is crucial for sound patch generation by LLMs—a 5/20 → 18/20 success rate improvement.</li><li><strong>Multi-Turn Retrieval Framework</strong>: We propose and train a novel multi-turn retrieval agent that iteratively retrieves concise, targeted code context, enabling effective utilization of powerful yet context-limited commercial LLMs.</li><li><strong>Effectiveness on Real-World Benchmarks</strong>: We demonstrate the efficacy of learned multi-turn retrieval through successful participation in the DARPA AIxCC competition, where context quality directly impacted patch success rates.</li></ol><h2 id=limitations-and-future-directions>Limitations and Future Directions</h2><p>Our approach has several practical limitations worth acknowledging:</p><ul><li><strong>Language Scope</strong>: Current implementation specializes for C codebases and hasn&rsquo;t been extended to other languages like Java or Python.</li><li><strong>Restricted Retrieval Scope</strong>: The retrieval process focuses only on function definitions, method definitions, and type definitions—potentially overlooking other useful artifacts like build scripts or configuration files.</li><li><strong>Tooling Overhead</strong>: Our use of parser-based tools required manual adapter development, limiting scalability. Broader, language-agnostic tools would improve generality.</li><li><strong>Catastrophic Forgetting</strong>: The online learning approach can degrade retrieval policies learned on earlier CPVs when adapting to new ones—a classic RL challenge.</li><li><strong>Competition Constraints</strong>: Late rule changes in the competition limited available custom model learning time and validation breadth.</li></ul><h3 id=future-research-opportunities>Future Research Opportunities</h3><p>The most exciting opportunities ahead:</p><ul><li><strong>Expanding Language Support</strong>: Adapting the retrieval framework to Java, Python, Rust, and other languages with appropriate parsers and symbol extraction tools.</li><li><strong>Richer Retrieval Actions</strong>: Beyond function and type definitions, retrieving documentation, test cases, commit history, and related patches could provide valuable context.</li><li><strong>Addressing Catastrophic Forgetting</strong>: Techniques like experience replay, progressive neural networks, or meta-learning could help retain knowledge across CPVs while adapting to new ones.</li><li><strong>Integrating with RAG Systems</strong>: Combining learned retrieval policies with retrieval-augmented generation could dynamically pull in relevant vulnerability patterns and exploitation knowledge.</li><li><strong>Human-in-the-Loop Refinement</strong>: Interactive systems where security experts guide retrieval strategies could accelerate learning and improve policy quality.</li></ul><h2 id=what-this-means-for-security>What This Means for Security</h2><p>Code context learning represents a fundamental shift from manual prompt engineering to adaptive, learnable approaches in AI-assisted security.</p><p>Instead of hand-crafting heuristics for what context matters, we&rsquo;re training specialized models to discover these patterns through reinforcement learning. The result? Systems that adapt to different bug types, codebases, and patching scenarios without constant human intervention.</p><p>This isn&rsquo;t just about patching faster—it&rsquo;s about patching smarter. As vulnerabilities grow more complex and codebases more massive, the ability to automatically identify and retrieve relevant context becomes critical for scalable automated security.</p><p>The future of security patching isn&rsquo;t about replacing human expertise—it&rsquo;s about teaching AI to learn what context matters, amplifying human judgment at machine scale. Custom models for code context learning represent one step toward that future.</p></div><div class="row items-start justify-between"><div class="lg:col-5 mb-10 flex items-center lg:mb-0"><h5 class=mr-3>Tags :</h5><ul><li class=inline-block><a class="bg-theme-light hover:bg-primary dark:bg-darkmode-theme-light dark:hover:bg-darkmode-primary dark:hover:text-dark m-1 block rounded px-3 py-1 hover:text-white" href=/tags/custom-model/>Custom model</a></li><li class=inline-block><a class="bg-theme-light hover:bg-primary dark:bg-darkmode-theme-light dark:hover:bg-darkmode-primary dark:hover:text-dark m-1 block rounded px-3 py-1 hover:text-white" href=/tags/llm/>Llm</a></li><li class=inline-block><a class="bg-theme-light hover:bg-primary dark:bg-darkmode-theme-light dark:hover:bg-darkmode-primary dark:hover:text-dark m-1 block rounded px-3 py-1 hover:text-white" href=/tags/reinforcement-learning/>Reinforcement learning</a></li><li class=inline-block><a class="bg-theme-light hover:bg-primary dark:bg-darkmode-theme-light dark:hover:bg-darkmode-primary dark:hover:text-dark m-1 block rounded px-3 py-1 hover:text-white" href=/tags/patch-generation/>Patch generation</a></li><li class=inline-block><a class="bg-theme-light hover:bg-primary dark:bg-darkmode-theme-light dark:hover:bg-darkmode-primary dark:hover:text-dark m-1 block rounded px-3 py-1 hover:text-white" href=/tags/context-learning/>Context learning</a></li></ul></div><div class="lg:col-4 flex items-center"><div class=share-icons><a class="share-link share-facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fteam-atlanta.github.io%2fblog%2fpost-custom-model%2f" target=_blank rel=noopener aria-label="share facebook"><span class=share-icon><svg viewBox="0 0 24 24"><path d="M18.77 7.46H14.5v-1.9c0-.9.6-1.1 1-1.1h3V.5h-4.33C10.24.5 9.5 3.44 9.5 5.32v2.15h-3v4h3v12h5v-12h3.85l.42-4z"/></svg>
</span></a><a class="share-link share-x" href="https://x.com/intent/tweet/?text=Share&amp;url=https%3a%2f%2fteam-atlanta.github.io%2fblog%2fpost-custom-model%2f" target=_blank rel=noopener aria-label="share x"><span aria-hidden=true class=share-icon><svg viewBox="0 0 24 24"><path d="M8 2H1l8.26 11.015L1.45 22H4.1l6.388-7.349L16 22h7l-8.608-11.478L21.8 2h-2.65l-5.986 6.886zm9 18L5 4h2l12 16z"/></svg>
</span></a><a class="share-link share-email" href="mailto:?subject=Share&amp;body=https%3a%2f%2fteam-atlanta.github.io%2fblog%2fpost-custom-model%2f" target=_self rel=noopener aria-label="share email"><span aria-hidden=true class=share-icon><svg viewBox="0 0 24 24"><path d="M22 4H2C.9 4 0 4.9.0 6v12c0 1.1.9 2 2 2h20c1.1.0 2-.9 2-2V6c0-1.1-.9-2-2-2zM7.25 14.43l-3.5 2c-.08.05-.17.07-.25.07-.17.0-.34-.1-.43-.25-.14-.24-.06-.55.18-.68l3.5-2c.24-.14.55-.06.68.18.14.24.06.55-.18.68zm4.75.07c-.1.0-.2-.03-.27-.08l-8.5-5.5c-.23-.15-.3-.46-.15-.7.15-.22.46-.3.7-.14L12 13.4l8.23-5.32c.23-.15.54-.08.7.15.14.23.07.54-.16.7l-8.5 5.5c-.08.04-.17.07-.27.07zm8.93 1.75c-.1.16-.26.25-.43.25-.08.0-.17-.02-.25-.07l-3.5-2c-.24-.13-.32-.44-.18-.68s.44-.32.68-.18l3.5 2c.24.13.32.44.18.68z"/></svg>
</span></a><a class="share-link share-reddit" href="https://reddit.com/submit/?url=https%3a%2f%2fteam-atlanta.github.io%2fblog%2fpost-custom-model%2f&amp;resubmit=true&amp;title=Share" target=_blank rel=noopener aria-label="share reddit"><span aria-hidden=true class=share-icon><svg viewBox="0 0 24 24"><path d="M24 11.5c0-1.65-1.35-3-3-3-.96.0-1.86.48-2.42 1.24-1.64-1-3.75-1.64-6.07-1.72.08-1.1.4-3.05 1.52-3.7.72-.4 1.73-.24 3 .5C17.2 6.3 18.46 7.5 20 7.5c1.65.0 3-1.35 3-3s-1.35-3-3-3c-1.38.0-2.54.94-2.88 2.22-1.43-.72-2.64-.8-3.6-.25-1.64.94-1.95 3.47-2 4.55-2.33.08-4.45.7-6.1 1.72C4.86 8.98 3.96 8.5 3 8.5c-1.65.0-3 1.35-3 3 0 1.32.84 2.44 2.05 2.84-.03.22-.05.44-.05.66.0 3.86 4.5 7 10 7s10-3.14 10-7c0-.22-.02-.44-.05-.66 1.2-.4 2.05-1.54 2.05-2.84zM2.3 13.37C1.5 13.07 1 12.35 1 11.5c0-1.1.9-2 2-2 .64.0 1.22.32 1.6.82-1.1.85-1.92 1.9-2.3 3.05zm3.7.13c0-1.1.9-2 2-2s2 .9 2 2-.9 2-2 2-2-.9-2-2zm9.8 4.8c-1.08.63-2.42.96-3.8.96-1.4.0-2.74-.34-3.8-.95-.24-.13-.32-.44-.2-.68.15-.24.46-.32.7-.18 1.83 1.06 4.76 1.06 6.6.0.23-.13.53-.05.67.2.14.23.06.54-.18.67zm.2-2.8c-1.1.0-2-.9-2-2s.9-2 2-2 2 .9 2 2-.9 2-2 2zm5.7-2.13c-.38-1.16-1.2-2.2-2.3-3.05.38-.5.97-.82 1.6-.82 1.1.0 2 .9 2 2 0 .84-.53 1.57-1.3 1.87z"/></svg>
</span></a><a class="share-link share-linkedin" href="https://www.linkedin.com/sharing/share-offsite/?url=https%3a%2f%2fteam-atlanta.github.io%2fblog%2fpost-custom-model%2f" target=_blank rel=noopener aria-label="share linkedin"><span aria-hidden=true class=share-icon><svg viewBox="0 0 24 24"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853.0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601.0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433A2.062 2.062.0 013.274 5.368a2.064 2.064.0 112.063 2.065m1.782 13.019H3.555V9h3.564zM22.225.0H1.771C.792.0.0.774.0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2.0 22.222.0z"/></svg>
</span></a><a class="share-link share-pinterest" href="http://pinterest.com/pin/create/link/?url=https%3a%2f%2fteam-atlanta.github.io%2fblog%2fpost-custom-model%2f" target=_blank rel=noopener aria-label="share linkedin"><span aria-hidden=true class=share-icon><svg viewBox="0 0 24 24"><path d="M12.017.0C5.396.0.029 5.367.029 11.987c0 5.079 3.158 9.417 7.618 11.162-.105-.949-.199-2.403.041-3.439.219-.937 1.406-5.957 1.406-5.957s-.359-.72-.359-1.781c0-1.663.967-2.911 2.168-2.911 1.024.0 1.518.769 1.518 1.688.0 1.029-.653 2.567-.992 3.992-.285 1.193.6 2.165 1.775 2.165 2.128.0 3.768-2.245 3.768-5.487.0-2.861-2.063-4.869-5.008-4.869-3.41.0-5.409 2.562-5.409 5.199.0 1.033.394 2.143.889 2.741.099.12.112.225.085.345-.09.375-.293 1.199-.334 1.363-.053.225-.172.271-.401.165-1.495-.69-2.433-2.878-2.433-4.646.0-3.776 2.748-7.252 7.92-7.252 4.158.0 7.392 2.967 7.392 6.923.0 4.135-2.607 7.462-6.233 7.462-1.214.0-2.354-.629-2.758-1.379l-.749 2.848c-.269 1.045-1.004 2.352-1.498 3.146 1.123.345 2.306.535 3.55.535 6.607.0 11.985-5.365 11.985-11.987C23.97 5.39 18.592.026 11.985.026z"/></svg>
</span></a><a class="share-link share-tumblr" href="https://www.tumblr.com/widgets/share/tool?canonicalUrl=https%3a%2f%2fteam-atlanta.github.io%2fblog%2fpost-custom-model%2f&title=Share" target=_blank rel=noopener aria-label="share linkedin"><span aria-hidden=true class=share-icon><svg viewBox="0 0 20 20"><path d="M10 .4C4.698.4.4 4.698.4 10s4.298 9.6 9.6 9.6 9.6-4.298 9.6-9.6S15.302.4 10 .4m2.577 13.741a5.508 5.508.0 01-1.066.395 4.543 4.543.0 01-1.031.113c-.42.0-.791-.055-1.114-.162a2.373 2.373.0 01-.826-.459 1.651 1.651.0 01-.474-.633c-.088-.225-.132-.549-.132-.973V9.16H6.918V7.846c.359-.119.67-.289.927-.512.257-.221.464-.486.619-.797.156-.31.263-.707.322-1.185h1.307v2.35h2.18V9.16h-2.18v2.385c0 .539.028.885.085 1.037a.7.7.0 00.315.367c.204.123.437.185.697.185.466.0.928-.154 1.388-.461z"/></svg>
</span></a><a class="share-link share-vk" href="http://vk.com/share.php?url=https%3a%2f%2fteam-atlanta.github.io%2fblog%2fpost-custom-model%2f&title=Share" target=_blank rel=noopener aria-label="share linkedin"><span aria-hidden=true class=share-icon><svg viewBox="0 0 24 24"><path d="M15.684.0H8.316C1.592.0.0 1.592.0 8.316v7.368C0 22.408 1.592 24 8.316 24h7.368C22.408 24 24 22.408 24 15.684V8.316C24 1.592 22.391.0 15.684.0zm3.692 17.123h-1.744c-.66.0-.864-.525-2.05-1.727-1.033-1-1.49-1.135-1.744-1.135-.356.0-.458.102-.458.593v1.575c0 .424-.135.678-1.253.678-1.846.0-3.896-1.118-5.335-3.202C4.624 10.857 4.03 8.57 4.03 8.096c0-.254.102-.491.593-.491h1.744c.44.0.61.203.78.677.863 2.49 2.303 4.675 2.896 4.675.22.0.322-.102.322-.66V9.721c-.068-1.186-.695-1.287-.695-1.71.0-.204.17-.407.44-.407h2.744c.373.0.508.203.508.643v3.473c0 .372.17.508.271.508.22.0.407-.136.813-.542 1.254-1.406 2.151-3.574 2.151-3.574.119-.254.322-.491.763-.491h1.744c.525.0.644.27.525.643-.22 1.017-2.354 4.031-2.354 4.031-.186.305-.254.44.0.78.186.254.796.779 1.203 1.253.745.847 1.32 1.558 1.473 2.05.17.49-.085.744-.576.744z"/></svg>
</span></a><span class=fediverse-share><a class="share-link share-fediverse" href=javascript:void(0); onclick=toggleFediverseInput(this) aria-label="share fediverse"><span aria-hidden=true class=share-icon><svg viewBox="-10 -5 1034 1034" xmlns:xlink="http://www.w3.org/1999/xlink"><g id="SVGRepo_bgCarrier" stroke-width="0"/><g id="SVGRepo_tracerCarrier" stroke-linecap="round" stroke-linejoin="round"/><g id="SVGRepo_iconCarrier"><path d="M539 176q-32 0-55 22t-25 55 20.5 58 56 27 58.5-20.5 27-56-20.5-59T544 176h-5zm-87 95-232 118q20 20 25 48l231-118q-19-20-24-48zm167 27q-13 25-38 38l183 184q13-25 39-38zM477 320 342 585l40 40 143-280q-28-5-48-25zm104 16q-22 11-46 10l-8-1 21 132 56 9zM155 370q-32 0-55 22.5t-25 55 20.5 58 56.5 27 59-21 26.5-56-21-58.5-55.5-27h-6zm90 68q1 9 1 18-1 19-10 35l132 21 26-50zm225 36-26 51 311 49q-1-8-1-17 1-19 10-36zm372 6q-32 1-55 23t-24.5 55 21 58 56 27 58.5-20.5 27-56.5-20.5-59-56.5-27h-6zM236 493q-13 25-39 38l210 210 51-25zm-40 38q-21 11-44 10l-9-1 40 256q21-10 45-9l8 1zm364 22 48 311q21-10 44-9l10 1-46-294zm195 23-118 60 8 56 135-68q-20-20-25-48zm26 49-119 231q28 5 48 25l119-231q-28-5-48-25zM306 654l-68 134q28 5 48 25l60-119zm262 17-281 143q19 20 24 48l265-135zM513 771l-51 25 106 107q13-25 39-38zM222 795q-32 0-55.5 22.5t-25 55 21 57.5 56 27 58.5-20.5 27-56-20.5-58.5-56.5-27h-5zm89 68q2 9 1 18-1 19-9 35l256 41q-1-9-1-18 1-18 10-35zm335 0q-32 0-55 22.5t-24.5 55 20.5 58 56 27 59-21 27-56-20.5-58.5-56.5-27h-6z"/></g></svg>
</span></a><span class=fediverse-input-wrapper style=display:none><input type=text placeholder="Enter Fediverse Instance URL" class=fediverse-input onkeypress='handleFediverseShare(event,"https://team-atlanta.github.io/blog/post-custom-model/","Share")'>
<button class=fediverse-check-button onclick='handleFediverseShareButton(this,"https://team-atlanta.github.io/blog/post-custom-model/","Share")'>
Share
</button>
</span></span><button class="share-link share-copy" onclick='copyToClipboard(this,"https://team-atlanta.github.io/blog/post-custom-model/")'>
<span class=share-icon><svg viewBox="0 0 24 24"><path d="M19 3h-4.18C14.4 1.84 13.3 1 12 1s-2.4.84-2.82 2H5c-1.1.0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1.0 2-.9 2-2V5c0-1.1-.9-2-2-2zm-7-1c.55.0 1 .45 1 1s-.45 1-1 1-1-.45-1-1 .45-1 1-1zm7 17H5V5h14v14z"/></svg></span></button></div><script>function toggleFediverseInput(e){const n=e.closest(".fediverse-share"),t=n.querySelector(".fediverse-input-wrapper");t.style.display=t.style.display==="none"?"block":"none"}function handleFediverseShare(e,t,n){if(e.key==="Enter"){const o=e.target;let s=o.value.trim();if(s){s.startsWith("https://")||(s=`https://${s}`);const e=`${s}/share?text=${encodeURIComponent(n)}&url=${encodeURIComponent(t)}`;window.open(e,"_blank","noopener")}}}function handleFediverseShareButton(e,t,n){const o=e.previousElementSibling;let s=o.value.trim();if(s){s.startsWith("https://")||(s=`https://${s}`);const e=`${s}/share?text=${encodeURIComponent(n)}&url=${encodeURIComponent(t)}`;window.open(e,"_blank","noopener")}}function copyToClipboard(e,t){navigator.clipboard.writeText(t).then(()=>{const t=e.querySelector("svg path"),n="M19 3h-4.18C14.4 1.84 13.3 1 12 1s-2.4.84-2.82 2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zm-7-1c.55 0 1 .45 1 1s-.45 1-1 1-1-.45-1-1 .45-1 1-1zm7 17H5V5h14v14z",s="M9 16.2l-3.5-3.5-1.4 1.4L9 19 20 8l-1.4-1.4L9 16.2z";t.setAttribute("d",s),setTimeout(()=>{t.setAttribute("d",n)},1e3)})}</script></div></div></article></div><div class="section pb-0"><h2 class="h3 mb-12">Related Posts</h2><div class=row><div class=lg:col-4><div class="blog-card-uniform glass-card p-6 group border border-gray-200/20 dark:border-gray-700/30 h-full"><div class="blog-card-content flex flex-col h-full"><div class="blog-card-image mb-4"><div class="relative overflow-hidden rounded-xl aspect-video"><picture><source srcset=/images/blog/mlla/cpua_preview_hu_2c9e22cd7acc217d.webp media="(max-width: 575px)"><source srcset=/images/blog/mlla/cpua_preview_hu_8b9c0051cfc4ffab.webp media="(max-width: 767px)"><source srcset=/images/blog/mlla/cpua_preview_hu_76a9f2a1986b6bc9.webp media="(max-width: 991px)"><source srcset=/images/blog/mlla/cpua_preview_hu_2dbd614d58a43d8a.webp><img loading=lazy decoding=async src=/images/blog/mlla/cpua_preview_hu_c4513d74d3477fa0.png class="w-full h-full object-cover group-hover:scale-105 transition-transform duration-300 img" alt="From Harness to Vulnerability: AI Agents for Code Comprehension and Bug Discovery" width=1024 height=1024></picture><div class="absolute inset-0 bg-gradient-to-t from-black/20 to-transparent opacity-0 group-hover:opacity-100 transition-opacity duration-300"></div></div></div><div class="blog-card-body flex-grow flex flex-col"><h4 class="blog-card-title mb-3 line-clamp-3 group-hover:text-primary transition-colors duration-300"><a href=/blog/post-mlla-disc-agents/ class="text-gray-900 dark:text-white hover:text-blue-600 dark:hover:text-blue-400 transition-colors duration-300 font-semibold text-lg leading-tight" title="From Harness to Vulnerability: AI Agents for Code Comprehension and Bug Discovery">From Harness to Vulnerability: AI Agents for Code Comprehension and Bug Discovery</a></h4><div class="blog-card-meta mb-4 text-sm text-gray-600 dark:text-gray-300 space-y-1"><div class="flex items-center min-h-[20px]"><a href=/authors/soyeon-park/ class="hover:text-blue-600 dark:hover:text-blue-400 transition-colors duration-300 flex items-center"><i class="fa-regular fa-circle-user mr-2 text-primary"></i>Soyeon Park</a></div><div class="flex items-center min-h-[20px]"><i class="fa-regular fa-folder mr-2 text-primary flex-shrink-0"></i><div class="flex flex-wrap items-center gap-x-1"><a href=/categories/atlantis-multilang/ class="hover:text-blue-600 dark:hover:text-blue-400 transition-colors duration-300">Atlantis multilang</a></div></div></div><p class="blog-card-summary mb-4 text-gray-700 dark:text-gray-300 leading-relaxed line-clamp-4 flex-grow">Beneath the Exploit: The Groundwork That Makes Bug Hunting Possible When people hear about AI agents finding vulnerabilities, they often imagine the spectacular finale: an exploit payload triggering a crash, or a carefully crafted generator slipping past validation layers.
But here’s the truth: none of that would have been possible without groundwork laid by three quieter agents.
Before any exploit can be created, the system must answer harder, subtler questions:</p></div><div class="blog-card-footer mt-auto"><a class="btn btn-outline-primary btn-sm hover:bg-gradient-modern hover:text-white hover:border-transparent transition-all duration-300 inline-flex items-center w-full justify-center" href=/blog/post-mlla-disc-agents/>Read More
<i class="fa fa-arrow-right ml-2 text-xs transition-transform duration-300 group-hover:translate-x-1"></i></a></div></div></div></div><div class=lg:col-4><div class="blog-card-uniform glass-card p-6 group border border-gray-200/20 dark:border-gray-700/30 h-full"><div class="blog-card-content flex flex-col h-full"><div class="blog-card-image mb-4"><div class="relative overflow-hidden rounded-xl aspect-video"><picture><source srcset=/images/blog/crs-java/libafl-jazzer/jazzer_plus_libafl_hu_382ebbbf5f489429.webp media="(max-width: 575px)"><source srcset=/images/blog/crs-java/libafl-jazzer/jazzer_plus_libafl_hu_d6be100e3efb493b.webp media="(max-width: 767px)"><source srcset=/images/blog/crs-java/libafl-jazzer/jazzer_plus_libafl_hu_85d33c2872aa7d6d.webp media="(max-width: 991px)"><source srcset=/images/blog/crs-java/libafl-jazzer/jazzer_plus_libafl_hu_9a86debab8eacf42.webp><img loading=lazy decoding=async src=/images/blog/crs-java/libafl-jazzer/jazzer_plus_libafl_hu_af41ab2119729508.png class="w-full h-full object-cover group-hover:scale-105 transition-transform duration-300 img" alt="Jazzer+LibAFL: Insights into Java Fuzzing" width=1100 height=700></picture><div class="absolute inset-0 bg-gradient-to-t from-black/20 to-transparent opacity-0 group-hover:opacity-100 transition-opacity duration-300"></div></div></div><div class="blog-card-body flex-grow flex flex-col"><h4 class="blog-card-title mb-3 line-clamp-3 group-hover:text-primary transition-colors duration-300"><a href=/blog/post-crs-java-libafl-jazzer/ class="text-gray-900 dark:text-white hover:text-blue-600 dark:hover:text-blue-400 transition-colors duration-300 font-semibold text-lg leading-tight" title="Jazzer+LibAFL: Insights into Java Fuzzing">Jazzer+LibAFL: Insights into Java Fuzzing</a></h4><div class="blog-card-meta mb-4 text-sm text-gray-600 dark:text-gray-300 space-y-1"><div class="flex items-center min-h-[20px]"><a href=/authors/ammar-askar/ class="hover:text-blue-600 dark:hover:text-blue-400 transition-colors duration-300 flex items-center"><i class="fa-regular fa-circle-user mr-2 text-primary"></i>Ammar Askar</a></div><div class="flex items-center min-h-[20px]"><i class="fa-regular fa-folder mr-2 text-primary flex-shrink-0"></i><div class="flex flex-wrap items-center gap-x-1"><a href=/categories/atlantis-java/ class="hover:text-blue-600 dark:hover:text-blue-400 transition-colors duration-300">Atlantis java</a></div></div></div><p class="blog-card-summary mb-4 text-gray-700 dark:text-gray-300 leading-relaxed line-clamp-4 flex-grow">AIxCC involved finding bugs in software written in two languages: C++ and Java. The focus of the competition was on the use of LLMs and AI, however, our teams approach was to balance ambitious strategies alongside proven traditional bug-finding techniques like fuzzing. While our team was deeply familiar with fuzzing C++ from decades of academic research and industry work, Java was uncharted territory for us. In part of our Java fuzzing development we created a fork of Jazzer that uses LibAFL as the fuzzing backend and it is available as part of our open source release. This post details some of the lessons we learned about Java fuzzing and the creation of this fork.</p></div><div class="blog-card-footer mt-auto"><a class="btn btn-outline-primary btn-sm hover:bg-gradient-modern hover:text-white hover:border-transparent transition-all duration-300 inline-flex items-center w-full justify-center" href=/blog/post-crs-java-libafl-jazzer/>Read More
<i class="fa fa-arrow-right ml-2 text-xs transition-transform duration-300 group-hover:translate-x-1"></i></a></div></div></div></div><div class=lg:col-4><div class="blog-card-uniform glass-card p-6 group border border-gray-200/20 dark:border-gray-700/30 h-full"><div class="blog-card-content flex flex-col h-full"><div class="blog-card-image mb-4"><div class="relative overflow-hidden rounded-xl aspect-video"><picture><source srcset=/images/blog/crs-java/overview/icon_hu_cba45d92e675516b.webp media="(max-width: 575px)"><source srcset=/images/blog/crs-java/overview/icon_hu_ba7e1021c7d3ed46.webp media="(max-width: 767px)"><source srcset=/images/blog/crs-java/overview/icon_hu_96fa6e80459d7dc2.webp media="(max-width: 991px)"><source srcset=/images/blog/crs-java/overview/icon_hu_642f822375e68259.webp><img loading=lazy decoding=async src=/images/blog/crs-java/overview/icon_hu_c61fd8d447e4289e.png class="w-full h-full object-cover group-hover:scale-105 transition-transform duration-300 img" alt="Atlantis-Java: A Sink-Centered Approach to Java Vulnerability Detection" width=1536 height=1024></picture><div class="absolute inset-0 bg-gradient-to-t from-black/20 to-transparent opacity-0 group-hover:opacity-100 transition-opacity duration-300"></div></div></div><div class="blog-card-body flex-grow flex flex-col"><h4 class="blog-card-title mb-3 line-clamp-3 group-hover:text-primary transition-colors duration-300"><a href=/blog/post-crs-java-overview/ class="text-gray-900 dark:text-white hover:text-blue-600 dark:hover:text-blue-400 transition-colors duration-300 font-semibold text-lg leading-tight" title="Atlantis-Java: A Sink-Centered Approach to Java Vulnerability Detection">Atlantis-Java: A Sink-Centered Approach to Java Vulnerability Detection</a></h4><div class="blog-card-meta mb-4 text-sm text-gray-600 dark:text-gray-300 space-y-1"><div class="flex items-center min-h-[20px]"><a href=/authors/cen-zhang/ class="hover:text-blue-600 dark:hover:text-blue-400 transition-colors duration-300 flex items-center"><i class="fa-regular fa-circle-user mr-2 text-primary"></i>Cen Zhang</a></div><div class="flex items-center min-h-[20px]"><i class="fa-regular fa-folder mr-2 text-primary flex-shrink-0"></i><div class="flex flex-wrap items-center gap-x-1"><a href=/categories/atlantis-java/ class="hover:text-blue-600 dark:hover:text-blue-400 transition-colors duration-300">Atlantis java</a></div></div></div><p class="blog-card-summary mb-4 text-gray-700 dark:text-gray-300 leading-relaxed line-clamp-4 flex-grow">Atlantis-Java is a specialized bug-finding subsystem within the Atlantis CRS framework, specifically designed for Java CPV detection in the AIxCC competition. It integrates fuzzing, program analysis, and LLM capabilities, with a particular focus on security-sensitive APIs (also known as sinks).
Many Java Vulnerabilities Are Sink-Centered Fig.1 Example CPV from AIxCC Semifinal Jenkins CP
This vulnerability contains a backdoor that enables OS command injection when specific conditions are met. The ProcessBuilder constructor serves as a sink API, where an attacker-controllable first argument can lead to arbitrary command execution. The sinkpoint (line 20) refers to the location in the target CP where this sink API is called.</p></div><div class="blog-card-footer mt-auto"><a class="btn btn-outline-primary btn-sm hover:bg-gradient-modern hover:text-white hover:border-transparent transition-all duration-300 inline-flex items-center w-full justify-center" href=/blog/post-crs-java-overview/>Read More
<i class="fa fa-arrow-right ml-2 text-xs transition-transform duration-300 group-hover:translate-x-1"></i></a></div></div></div></div></div></div></div></section></main><footer class=footer-modern><div class=container><div class="row items-center py-10"><div class="lg:col-3 mb-8 text-center lg:mb-0 lg:text-left"><a class="navbar-brand inline-block" href=/>Team Atlanta</a></div><div class="lg:col-6 mb-8 text-center lg:mb-0"><ul><li class="m-3 inline-block"><a href=/>Home</a></li><li class="m-3 inline-block"><a href=/authors/>AIxCC Team</a></li><li class="m-3 inline-block"><a href=/artifacts/>Research & Code</a></li><li class="m-3 inline-block"><a href=/news/>News</a></li><li class="m-3 inline-block"><a href=/blog/>Blog</a></li></ul></div><div class="lg:col-3 mb-8 text-center lg:mb-0 lg:mt-0 lg:text-right"><ul class=social-icons><li><a target=_blank aria-label=www rel="nofollow noopener" href=https://team-atlanta.github.io/><i class="fa-solid fa-house"></i></a></li><li><a target=_blank aria-label=github rel="nofollow noopener" href=https://github.com/Team-Atlanta/><i class="fab fa-github"></i></a></li><li><a target=_blank aria-label=twitter rel="nofollow noopener" href=https://x.com/TeamAtlanta24><i class="fab fa-twitter"></i></a></li><li><a target=_blank aria-label=linkedin rel="nofollow noopener" href=https://www.linkedin.com/company/team-atlanta><i class="fab fa-linkedin"></i></a></li></ul></div></div></div><div class="border-border dark:border-darkmode-border border-t py-7"><div class="text-light dark:text-darkmode-light container text-center"><p>© 2025 Team Atlanta. All rights reserved.</p></div></div></footer><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js type=application/javascript integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js type=application/javascript integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script crossorigin=anonymous integrity="sha256-ZzhlD7moLUKIEbE9GK0CDIM+smwZL6KInwVClcz07Fs=" src=/js/script.min.6738650fb9a82d428811b13d18ad020c833eb26c192fa2889f054295ccf4ec5b.js></script><script defer async crossorigin=anonymous integrity="sha256-jdGIvqRfmE+PJv6VBdrtg9czS/I65MhECJ3o5zEUJ5o=" src=/js/script-lazy.min.8dd188bea45f984f8f26fe9505daed83d7334bf23ae4c844089de8e73114279a.js></script><script>"serviceWorker"in navigator&&navigator.serviceWorker.register("/service-worker.js")</script></body></html>