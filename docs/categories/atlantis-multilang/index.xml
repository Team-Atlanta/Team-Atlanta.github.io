<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Atlantis-Multilang on Team Atlanta</title><link>https://team-atlanta.github.io/categories/atlantis-multilang/</link><description>Recent content in Atlantis-Multilang on Team Atlanta</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Thu, 28 Aug 2025 10:00:00 +0000</lastBuildDate><atom:link href="https://team-atlanta.github.io/categories/atlantis-multilang/index.xml" rel="self" type="application/rss+xml"/><item><title>MLLA: Teaching LLMs to Hunt Bugs Like Security Researchers</title><link>https://team-atlanta.github.io/blog/post-mlla-overview/</link><pubDate>Thu, 28 Aug 2025 10:00:00 +0000</pubDate><guid>https://team-atlanta.github.io/blog/post-mlla-overview/</guid><description>&lt;h2 id="when-fuzzing-meets-intelligence"&gt;When Fuzzing Meets Intelligence&lt;/h2&gt;
&lt;p&gt;Picture this: you&amp;rsquo;re a security researcher staring at 20 million lines of code, hunting for vulnerabilities that could compromise everything from your smartphone to critical infrastructure. Traditional fuzzers approach this challenge with brute force – throwing millions of random inputs at the program like a toddler mashing keyboard keys. Sometimes it works. Often, it doesn&amp;rsquo;t.&lt;/p&gt;
&lt;p&gt;But what if we could change the game entirely?&lt;/p&gt;
&lt;p&gt;&lt;span style="background-color:lightgray;color:green"&gt;Meet MLLA (Multi-Language LLM Agent) – the most ambitious experiment in AI-assisted vulnerability discovery we&amp;rsquo;ve ever built. Instead of random chaos, MLLA thinks, plans, and hunts bugs like an experienced security researcher, but at machine scale.&lt;/span&gt;&lt;/p&gt;</description></item><item><title>Atlantis-Multilang (UniAFL): LLM-powered &amp; Lauguage-agonistic Automatic Bug Finding</title><link>https://team-atlanta.github.io/blog/post-crs-multilang/</link><pubDate>Wed, 20 Aug 2025 05:00:00 +0000</pubDate><guid>https://team-atlanta.github.io/blog/post-crs-multilang/</guid><description>&lt;h2 id="atlantis-multilang--uniafl"&gt;Atlantis-Multilang == UniAFL&lt;/h2&gt;
&lt;p&gt;Atlantis-Multilang is a fuzzing framework called UniAFL, designed to LLMs for fuzzing across multiple programming languages.
Unlike Atlantis-C and Atlantis-Java, it avoids language-specific instrumentation and is intentionally built to be as language-agnostic as possible — both in design and execution.
&lt;span style="background-color:lightgray;color:green"&gt;Despite this broad and general approach, UniAFL proved to be highly effective in the AIxCC finals, contributing to 69.2% of all POV (Proof-of-Vulnerability) submissions.&lt;/span&gt;
This result highlights not only the flexibility of its design but also its strong performance in practice.
In this post, we’ll walk you through how we pulled it off, why we made these design choices, and what made UniAFL so effective in practice.&lt;/p&gt;</description></item></channel></rss>