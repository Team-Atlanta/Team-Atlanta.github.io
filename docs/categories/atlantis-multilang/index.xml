<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Atlantis-Multilang on Team Atlanta</title><link>https://team-atlanta.github.io/categories/atlantis-multilang/</link><description>Recent content in Atlantis-Multilang on Team Atlanta</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Tue, 02 Sep 2025 10:00:00 +0000</lastBuildDate><atom:link href="https://team-atlanta.github.io/categories/atlantis-multilang/index.xml" rel="self" type="application/rss+xml"/><item><title>Context Engineering: How BGA Teaches LLMs to Write Exploits</title><link>https://team-atlanta.github.io/blog/post-context-engineering/</link><pubDate>Tue, 02 Sep 2025 10:00:00 +0000</pubDate><guid>https://team-atlanta.github.io/blog/post-context-engineering/</guid><description>&lt;h2 id="the-problem-with-teaching-ai-to-hack"&gt;The Problem with Teaching AI to Hack&lt;/h2&gt;
&lt;p&gt;Teaching an LLM to write working exploits is more challenging than typical AI tasks. Unlike most applications where &amp;ldquo;close enough&amp;rdquo; works, vulnerability exploitation requires precise execution. A single character error can make an entire exploit fail.&lt;/p&gt;
&lt;p&gt;Take this seemingly simple Java reflective call injection vulnerability:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-java" data-lang="java"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;String className &lt;span style="color:#f92672"&gt;=&lt;/span&gt; request.&lt;span style="color:#a6e22e"&gt;getParameter&lt;/span&gt;(&lt;span style="color:#e6db74"&gt;&amp;#34;class&amp;#34;&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;Class.&lt;span style="color:#a6e22e"&gt;forName&lt;/span&gt;(className); &lt;span style="color:#75715e"&gt;// BUG: arbitrary class loading&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This looks straightforward, but there&amp;rsquo;s a catch: to exploit this vulnerability, the LLM must load the exact class name &lt;a href="https://github.com/CodeIntelligenceTesting/jazzer/blob/527fe858f700382f9207cf7c7bc6b95cf59de936/sanitizers/src/main/java/com/code_intelligence/jazzer/sanitizers/Utils.kt#L25"




 target="_blank"
 


&gt;&lt;code&gt;&amp;quot;jaz.Zer&amp;quot;&lt;/code&gt;&lt;/a&gt; to trigger &lt;a href="https://github.com/CodeIntelligenceTesting/jazzer"




 target="_blank"
 


&gt;Jazzer&lt;/a&gt;&amp;rsquo;s detection. Not &lt;code&gt;&amp;quot;jaz.Zero&amp;quot;&lt;/code&gt;, not &lt;code&gt;&amp;quot;java.Zer&amp;quot;&lt;/code&gt;, not &lt;code&gt;&amp;quot;jaz.zer&amp;quot;&lt;/code&gt;. One character wrong and the entire exploit fails.&lt;/p&gt;</description></item><item><title>BGA: Self-Evolving Exploits Through Multi-Agent AI</title><link>https://team-atlanta.github.io/blog/post-mlla-bga/</link><pubDate>Fri, 29 Aug 2025 10:00:00 +0000</pubDate><guid>https://team-atlanta.github.io/blog/post-mlla-bga/</guid><description>&lt;h2 id="why-programs-beat-payloads"&gt;Why Programs Beat Payloads&lt;/h2&gt;
&lt;p&gt;Here&amp;rsquo;s the problem that changed everything: you need an exploit with exactly 1000 &amp;lsquo;A&amp;rsquo; characters followed by shellcode. Ask an LLM to generate it directly, and you might get 847 A&amp;rsquo;s, maybe 1203 A&amp;rsquo;s – never quite right. But ask it to write &lt;code&gt;payload = &amp;quot;A&amp;quot; * 1000 + shellcode&lt;/code&gt;, and you get perfection every time.&lt;/p&gt;
&lt;p&gt;This insight sparked our breakthrough during the AIxCC competition. Instead of hoping AI could guess the right attack data, we taught it to write programs that create that data. The result? &lt;strong&gt;Seven unique vulnerabilities discovered&lt;/strong&gt; - exploits that evolved and adapted until they found their targets.&lt;/p&gt;</description></item><item><title>MLLA: Teaching LLMs to Hunt Bugs Like Security Researchers</title><link>https://team-atlanta.github.io/blog/post-mlla-overview/</link><pubDate>Thu, 28 Aug 2025 10:00:00 +0000</pubDate><guid>https://team-atlanta.github.io/blog/post-mlla-overview/</guid><description>&lt;h2 id="when-fuzzing-meets-intelligence"&gt;When Fuzzing Meets Intelligence&lt;/h2&gt;
&lt;p&gt;Picture this: you&amp;rsquo;re a security researcher staring at 20 million lines of code, hunting for vulnerabilities that could compromise everything from your smartphone to critical infrastructure. Traditional fuzzers approach this challenge with brute force – throwing millions of random inputs at the program like a toddler mashing keyboard keys. Sometimes it works. Often, it doesn&amp;rsquo;t.&lt;/p&gt;
&lt;p&gt;But what if we could change the game entirely?&lt;/p&gt;
&lt;p&gt;&lt;span style="background-color:lightgray;color:green"&gt;Meet MLLA (Multi-Language LLM Agent) – the most ambitious experiment in AI-assisted vulnerability discovery we&amp;rsquo;ve ever built. Instead of random chaos, MLLA thinks, plans, and hunts bugs like an experienced security researcher, but at machine scale.&lt;/span&gt;&lt;/p&gt;</description></item><item><title>Atlantis-Multilang (UniAFL): LLM-powered &amp; Lauguage-agonistic Automatic Bug Finding</title><link>https://team-atlanta.github.io/blog/post-crs-multilang/</link><pubDate>Wed, 20 Aug 2025 05:00:00 +0000</pubDate><guid>https://team-atlanta.github.io/blog/post-crs-multilang/</guid><description>&lt;h2 id="atlantis-multilang--uniafl"&gt;Atlantis-Multilang == UniAFL&lt;/h2&gt;
&lt;p&gt;Atlantis-Multilang is a fuzzing framework called UniAFL, designed to LLMs for fuzzing across multiple programming languages.
Unlike Atlantis-C and Atlantis-Java, it avoids language-specific instrumentation and is intentionally built to be as language-agnostic as possible — both in design and execution.
&lt;span style="background-color:lightgray;color:green"&gt;Despite this broad and general approach, UniAFL proved to be highly effective in the AIxCC finals, contributing to 69.2% of all POV (Proof-of-Vulnerability) submissions.&lt;/span&gt;
This result highlights not only the flexibility of its design but also its strong performance in practice.
In this post, we’ll walk you through how we pulled it off, why we made these design choices, and what made UniAFL so effective in practice.&lt;/p&gt;</description></item></channel></rss>