<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Multi-Agent on Team Atlanta</title><link>https://team-atlanta.github.io/tags/multi-agent/</link><description>Recent content in Multi-Agent on Team Atlanta</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Fri, 29 Aug 2025 10:00:00 +0000</lastBuildDate><atom:link href="https://team-atlanta.github.io/tags/multi-agent/index.xml" rel="self" type="application/rss+xml"/><item><title>BGA: Self-Evolving Exploits Through Multi-Agent AI</title><link>https://team-atlanta.github.io/blog/post-mlla-bga/</link><pubDate>Fri, 29 Aug 2025 10:00:00 +0000</pubDate><guid>https://team-atlanta.github.io/blog/post-mlla-bga/</guid><description>&lt;h2 id="why-programs-beat-payloads"&gt;Why Programs Beat Payloads&lt;/h2&gt;
&lt;p&gt;Here&amp;rsquo;s the problem that changed everything: you need an exploit with exactly 1000 &amp;lsquo;A&amp;rsquo; characters followed by shellcode. Ask an LLM to generate it directly, and you might get 847 A&amp;rsquo;s, maybe 1203 A&amp;rsquo;s – never quite right. But ask it to write &lt;code&gt;payload = &amp;quot;A&amp;quot; * 1000 + shellcode&lt;/code&gt;, and you get perfection every time.&lt;/p&gt;
&lt;p&gt;This insight sparked our breakthrough during the AIxCC competition. Instead of hoping AI could guess the right attack data, we taught it to write programs that create that data. The result? &lt;strong&gt;Seven unique vulnerabilities discovered&lt;/strong&gt; - exploits that evolved and adapted until they found their targets.&lt;/p&gt;</description></item><item><title>MLLA: Teaching LLMs to Hunt Bugs Like Security Researchers</title><link>https://team-atlanta.github.io/blog/post-mlla-overview/</link><pubDate>Thu, 28 Aug 2025 10:00:00 +0000</pubDate><guid>https://team-atlanta.github.io/blog/post-mlla-overview/</guid><description>&lt;h2 id="when-fuzzing-meets-intelligence"&gt;When Fuzzing Meets Intelligence&lt;/h2&gt;
&lt;p&gt;Picture this: you&amp;rsquo;re a security researcher staring at 20 million lines of code, hunting for vulnerabilities that could compromise everything from your smartphone to critical infrastructure. Traditional fuzzers approach this challenge with brute force – throwing millions of random inputs at the program like a toddler mashing keyboard keys. Sometimes it works. Often, it doesn&amp;rsquo;t.&lt;/p&gt;
&lt;p&gt;But what if we could change the game entirely?&lt;/p&gt;
&lt;p&gt;&lt;span style="background-color:lightgray;color:green"&gt;Meet MLLA (Multi-Language LLM Agent) – the most ambitious experiment in AI-assisted vulnerability discovery we&amp;rsquo;ve ever built. Instead of random chaos, MLLA thinks, plans, and hunts bugs like an experienced security researcher, but at machine scale.&lt;/span&gt;&lt;/p&gt;</description></item></channel></rss>