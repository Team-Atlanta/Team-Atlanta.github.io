<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Multi-Agent on Team Atlanta</title><link>https://team-atlanta.github.io/tags/multi-agent/</link><description>Recent content in Multi-Agent on Team Atlanta</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Fri, 10 Oct 2025 11:00:00 +0000</lastBuildDate><atom:link href="https://team-atlanta.github.io/tags/multi-agent/index.xml" rel="self" type="application/rss+xml"/><item><title>Vincent, One Puzzle for Our Ensemble Toward High-quality Patches</title><link>https://team-atlanta.github.io/blog/post-crs-patch-agent-vincent/</link><pubDate>Fri, 10 Oct 2025 11:00:00 +0000</pubDate><guid>https://team-atlanta.github.io/blog/post-crs-patch-agent-vincent/</guid><description>&lt;p>As mentioned in the previous post, our strategy for patching is to prepare multiple agents to ensure both the robustness and correctness of the system.
To this end, we developed various patch agents, each specialized for different LLM models and tools.&lt;/p>
&lt;p>In this post, we would like to introduce Vincent agent, one of the patch agents running under our ensemble-based patching system.&lt;/p>
&lt;h2 id="right-root-cause-wrong-patches">Right Root cause, Wrong Patches&lt;/h2>
&lt;p>What surprised us during the competition was that LLMs alone are already quite doing well at generating proper patches.
Given a sanitizer report, LLMs could freely explore the codebase by itself and reason correctly about the given bugâ€”especially when the problematic code appeared near the call stacks in the report.&lt;/p></description></item><item><title>Ensembles of Agents for Robust and Effective Automated Patching</title><link>https://team-atlanta.github.io/blog/post-crs-patch-integration/</link><pubDate>Sun, 05 Oct 2025 11:00:00 +0000</pubDate><guid>https://team-atlanta.github.io/blog/post-crs-patch-integration/</guid><description>&lt;h2 id="why-ensemble-for-patching">Why Ensemble for Patching?&lt;/h2>
&lt;p>In the AIxCC competition, finding vulnerabilities is only half the battle. Once a vulnerability is discovered, it must be patched to prevent exploitation. This is where the Atlantis-Patching system comes into play. As the AIxCC&amp;rsquo;s ultimate mission is to make software secure, it awards more points for patching vulnerabilities than for finding them. In particular, the competition rewards &lt;strong>6 points&lt;/strong> for patching a vulnerability, compared to just 2 points for discovering it. As a result, to win the competition, it is crucial to have a robust and efficient patching system that can quickly generate effective patches for discovered vulnerabilities.&lt;/p></description></item><item><title>BCDA: The AI Detective Separating Real Bugs from False Alarms</title><link>https://team-atlanta.github.io/blog/post-mlla-bcda/</link><pubDate>Sun, 07 Sep 2025 11:00:00 +0000</pubDate><guid>https://team-atlanta.github.io/blog/post-mlla-bcda/</guid><description>&lt;h2 id="-from-potential-sink-to-actionable-intelligence">ðŸŽ¯ From Potential Sink to Actionable Intelligence&lt;/h2>
&lt;p>BCDA (Bug Candidate Detection Agent)&amp;rsquo;s core mission is to address the fundamental challenge of lightweight sink analysis: distinguishing real vulnerabilities from false-positive noise.
When MCGA, our cartographer, flags a function containing a potentially vulnerable &amp;ldquo;sink&amp;rdquo; (such as a function that executes system commands), BCDA takes over.&lt;/p>
&lt;p>Its job isn&amp;rsquo;t just to say &amp;ldquo;yes&amp;rdquo; or &amp;ldquo;no.&amp;rdquo;
BCDA performs a deep, multi-stage investigation powered by LLMs to produce a &lt;strong>Bug Inducing Thing (BIT)&lt;/strong>.
A BIT is a high-fidelity, structured report detailing a confirmed vulnerability candidate.
It includes the exact location, the specific trigger conditions (like &lt;code>if-else&lt;/code> branches), and a detailed analysis generated by LLMs.
This report becomes a detailed guide for our demolition expert, BGA, and the fuzzing stages.&lt;/p></description></item><item><title>From Harness to Vulnerability: AI Agents for Code Comprehension and Bug Discovery</title><link>https://team-atlanta.github.io/blog/post-mlla-disc-agents/</link><pubDate>Thu, 04 Sep 2025 10:00:00 +0000</pubDate><guid>https://team-atlanta.github.io/blog/post-mlla-disc-agents/</guid><description>&lt;h2 id="beneath-the-exploit-the-groundwork-that-makes-bug-hunting-possible">&lt;strong>Beneath the Exploit: The Groundwork That Makes Bug Hunting Possible&lt;/strong>&lt;/h2>
&lt;p>When people hear about &lt;strong>AI agents finding vulnerabilities&lt;/strong>, they often imagine the spectacular finale: an exploit payload triggering a crash, or a carefully crafted generator slipping past validation layers.&lt;/p>
&lt;p>But hereâ€™s the truth: &lt;strong>none of that would have been possible without groundwork laid by three quieter agents.&lt;/strong>&lt;/p>
&lt;p>Before any exploit can be created, the system must answer harder, subtler questions:&lt;/p></description></item><item><title>BGA: Self-Evolving Exploits Through Multi-Agent AI</title><link>https://team-atlanta.github.io/blog/post-mlla-bga/</link><pubDate>Fri, 29 Aug 2025 10:00:00 +0000</pubDate><guid>https://team-atlanta.github.io/blog/post-mlla-bga/</guid><description>&lt;h2 id="-where-bga-fits-in-the-mlla-pipeline">ðŸ”„ Where BGA Fits in the MLLA Pipeline&lt;/h2>
&lt;p>Before we dive into BGA&amp;rsquo;s self-evolving exploits, here&amp;rsquo;s how it fits into the broader MLLA vulnerability discovery pipeline:&lt;/p>
&lt;p>&lt;strong>Discovery Agents&lt;/strong> (&lt;a href="https://team-atlanta.github.io/blog/post-mlla-disc-agents/"




 target="_blank"
 


>CPUA, MCGA, CGPA&lt;/a>) â†’ &lt;strong>Detective&lt;/strong> (&lt;a href="https://team-atlanta.github.io/blog/post-mlla-bcda/"




 target="_blank"
 


>BCDA&lt;/a>) â†’ &lt;strong>Exploit Generation&lt;/strong> (&lt;strong>BGA&lt;/strong>)&lt;/p>
&lt;ol>
&lt;li>&lt;strong>Discovery agents&lt;/strong> map the codebase and identify potential vulnerability paths&lt;/li>
&lt;li>&lt;strong>BCDA&lt;/strong> investigates these paths, filtering false positives and creating Bug Inducing Things (BITs) with precise trigger conditions&lt;/li>
&lt;li>&lt;strong>BGA&lt;/strong> receives these confirmed vulnerabilities and generates self-evolving exploits to trigger them&lt;/li>
&lt;/ol>
&lt;p>Now BGA takes the stage, armed with BCDA&amp;rsquo;s detailed intelligence about exactly what conditions must be satisfied to reach each vulnerability.&lt;/p></description></item><item><title>MLLA: Teaching LLMs to Hunt Bugs Like Security Researchers</title><link>https://team-atlanta.github.io/blog/post-mlla-overview/</link><pubDate>Thu, 28 Aug 2025 10:00:00 +0000</pubDate><guid>https://team-atlanta.github.io/blog/post-mlla-overview/</guid><description>&lt;h2 id="when-fuzzing-meets-intelligence">When Fuzzing Meets Intelligence&lt;/h2>
&lt;p>Picture this: you&amp;rsquo;re a security researcher staring at 20 million lines of code, hunting for vulnerabilities that could compromise everything from your smartphone to critical infrastructure. Traditional fuzzers approach this challenge with brute force â€“ throwing millions of random inputs at the program like a toddler mashing keyboard keys. Sometimes it works. Often, it doesn&amp;rsquo;t.&lt;/p>
&lt;p>But what if we could change the game entirely?&lt;/p>
&lt;p>&lt;span style="background-color:lightgray;color:green">Meet MLLA (Multi-Language LLM Agent) â€“ the most ambitious experiment in AI-assisted vulnerability discovery we&amp;rsquo;ve ever built. Instead of random chaos, MLLA thinks, plans, and hunts bugs like an experienced security researcher, but at machine scale.&lt;/span>&lt;/p></description></item></channel></rss>